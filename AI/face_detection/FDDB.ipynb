{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# This function is modified from the following code snippet:\n",
    "# https://github.com/StanislasBertrand/RetinaFace-tf2/blob/5f68ce8130889384cb8aca937a270cea4ef2d020/retinaface.py#L49-L74\n",
    "def resize_image(img, scales, allow_upscaling):\n",
    "    img_h, img_w = img.shape[0:2]\n",
    "    target_size = scales[0]\n",
    "    max_size = scales[1]\n",
    "\n",
    "    if img_w > img_h:\n",
    "        im_size_min, im_size_max = img_h, img_w\n",
    "    else:\n",
    "        im_size_min, im_size_max = img_w, img_h\n",
    "\n",
    "    im_scale = target_size / float(im_size_min)\n",
    "    if not allow_upscaling:\n",
    "        im_scale = min(1.0, im_scale)\n",
    "\n",
    "    if np.round(im_scale * im_size_max) > max_size:\n",
    "        im_scale = max_size / float(im_size_max)\n",
    "\n",
    "    if im_scale != 1.0:\n",
    "        img = cv2.resize(\n",
    "            img,\n",
    "            None,\n",
    "            None,\n",
    "            fx=im_scale,\n",
    "            fy=im_scale,\n",
    "            interpolation=cv2.INTER_LINEAR\n",
    "        )\n",
    "\n",
    "    return img, im_scale\n",
    "\n",
    "\n",
    "# This function is modified from the following code snippet:\n",
    "# https://github.com/StanislasBertrand/RetinaFace-tf2/blob/5f68ce8130889384cb8aca937a270cea4ef2d020/retinaface.py#L76-L96\n",
    "def preprocess_image(img, allow_upscaling):\n",
    "    pixel_means = np.array([0.0, 0.0, 0.0], dtype=np.float32)\n",
    "    pixel_stds = np.array([1.0, 1.0, 1.0], dtype=np.float32)\n",
    "    pixel_scale = float(1.0)\n",
    "    scales = [1024, 1980]\n",
    "\n",
    "    img, im_scale = resize_image(img, scales, allow_upscaling)\n",
    "    img = img.astype(np.float32)\n",
    "    im_tensor = np.zeros((1, img.shape[0], img.shape[1], img.shape[2]), dtype=np.float32)\n",
    "\n",
    "    # Make image scaling + BGR2RGB conversion + transpose (N,H,W,C) to (N,C,H,W)\n",
    "    for i in range(3):\n",
    "        im_tensor[0, :, :, i] = (img[:, :, 2 - i] / pixel_scale - pixel_means[2 - i]) / pixel_stds[2 - i]\n",
    "\n",
    "    return im_tensor, img.shape[0:2], im_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance\n",
    "\n",
    "#this function copied from the deepface repository: https://github.com/serengil/deepface/blob/master/deepface/commons/functions.py\n",
    "def alignment_procedure(img, left_eye, right_eye, nose):\n",
    "\n",
    "    #this function aligns given face in img based on left and right eye coordinates\n",
    "\n",
    "    #left eye is the eye appearing on the left (right eye of the person)\n",
    "    #left top point is (0, 0)\n",
    "\n",
    "    left_eye_x, left_eye_y = left_eye\n",
    "    right_eye_x, right_eye_y = right_eye\n",
    "\n",
    "    #-----------------------\n",
    "    #decide the image is inverse\n",
    "\n",
    "    center_eyes = (int((left_eye_x + right_eye_x) / 2), int((left_eye_y + right_eye_y) / 2))\n",
    "    \n",
    "    if False:\n",
    "\n",
    "        img = cv2.circle(img, (int(left_eye[0]), int(left_eye[1])), 2, (0, 255, 255), 2)\n",
    "        img = cv2.circle(img, (int(right_eye[0]), int(right_eye[1])), 2, (255, 0, 0), 2)\n",
    "        img = cv2.circle(img, center_eyes, 2, (0, 0, 255), 2)\n",
    "        img = cv2.circle(img, (int(nose[0]), int(nose[1])), 2, (255, 255, 255), 2)\n",
    "\n",
    "    #-----------------------\n",
    "    #find rotation direction\n",
    "\n",
    "    if left_eye_y > right_eye_y:\n",
    "        point_3rd = (right_eye_x, left_eye_y)\n",
    "        direction = -1 #rotate same direction to clock\n",
    "    else:\n",
    "        point_3rd = (left_eye_x, right_eye_y)\n",
    "        direction = 1 #rotate inverse direction of clock\n",
    "\n",
    "    #-----------------------\n",
    "    #find length of triangle edges\n",
    "\n",
    "    a = findEuclideanDistance(np.array(left_eye), np.array(point_3rd))\n",
    "    b = findEuclideanDistance(np.array(right_eye), np.array(point_3rd))\n",
    "    c = findEuclideanDistance(np.array(right_eye), np.array(left_eye))\n",
    "\n",
    "    #-----------------------\n",
    "\n",
    "    #apply cosine rule\n",
    "\n",
    "    if b != 0 and c != 0: #this multiplication causes division by zero in cos_a calculation\n",
    "\n",
    "        cos_a = (b*b + c*c - a*a)/(2*b*c)\n",
    "        \n",
    "        #PR15: While mathematically cos_a must be within the closed range [-1.0, 1.0], floating point errors would produce cases violating this\n",
    "        #In fact, we did come across a case where cos_a took the value 1.0000000169176173, which lead to a NaN from the following np.arccos step\n",
    "        cos_a = min(1.0, max(-1.0, cos_a))\n",
    "        \n",
    "        \n",
    "        angle = np.arccos(cos_a) #angle in radian\n",
    "        angle = (angle * 180) / math.pi #radian to degree\n",
    "\n",
    "        #-----------------------\n",
    "        #rotate base image\n",
    "\n",
    "        if direction == -1:\n",
    "            angle = 90 - angle\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        img = np.array(img.rotate(direction * angle))\n",
    "\n",
    "    #-----------------------\n",
    "\n",
    "    return img #return img anyway\n",
    "\n",
    "#this function is copied from the following code snippet: https://github.com/StanislasBertrand/RetinaFace-tf2/blob/master/retinaface.py\n",
    "def bbox_pred(boxes, box_deltas):\n",
    "    if boxes.shape[0] == 0:\n",
    "        return np.zeros((0, box_deltas.shape[1]))\n",
    "\n",
    "    boxes = boxes.astype(float, copy=False)\n",
    "    widths = boxes[:, 2] - boxes[:, 0] + 1.0\n",
    "    heights = boxes[:, 3] - boxes[:, 1] + 1.0\n",
    "    ctr_x = boxes[:, 0] + 0.5 * (widths - 1.0)\n",
    "    ctr_y = boxes[:, 1] + 0.5 * (heights - 1.0)\n",
    "\n",
    "    dx = box_deltas[:, 0:1]\n",
    "    dy = box_deltas[:, 1:2]\n",
    "    dw = box_deltas[:, 2:3]\n",
    "    dh = box_deltas[:, 3:4]\n",
    "\n",
    "    pred_ctr_x = dx * widths[:, np.newaxis] + ctr_x[:, np.newaxis]\n",
    "    pred_ctr_y = dy * heights[:, np.newaxis] + ctr_y[:, np.newaxis]\n",
    "    pred_w = np.exp(dw) * widths[:, np.newaxis]\n",
    "    pred_h = np.exp(dh) * heights[:, np.newaxis]\n",
    "\n",
    "    pred_boxes = np.zeros(box_deltas.shape)\n",
    "    # x1\n",
    "    pred_boxes[:, 0:1] = pred_ctr_x - 0.5 * (pred_w - 1.0)\n",
    "    # y1\n",
    "    pred_boxes[:, 1:2] = pred_ctr_y - 0.5 * (pred_h - 1.0)\n",
    "    # x2\n",
    "    pred_boxes[:, 2:3] = pred_ctr_x + 0.5 * (pred_w - 1.0)\n",
    "    # y2\n",
    "    pred_boxes[:, 3:4] = pred_ctr_y + 0.5 * (pred_h - 1.0)\n",
    "\n",
    "    if box_deltas.shape[1]>4:\n",
    "        pred_boxes[:,4:] = box_deltas[:,4:]\n",
    "\n",
    "    return pred_boxes\n",
    "\n",
    "# This function copied from the following code snippet: https://github.com/StanislasBertrand/RetinaFace-tf2/blob/master/retinaface.py\n",
    "def landmark_pred(boxes, landmark_deltas):\n",
    "    if boxes.shape[0] == 0:\n",
    "      return np.zeros((0, landmark_deltas.shape[1]))\n",
    "    boxes = boxes.astype(float, copy=False)\n",
    "    widths = boxes[:, 2] - boxes[:, 0] + 1.0\n",
    "    heights = boxes[:, 3] - boxes[:, 1] + 1.0\n",
    "    ctr_x = boxes[:, 0] + 0.5 * (widths - 1.0)\n",
    "    ctr_y = boxes[:, 1] + 0.5 * (heights - 1.0)\n",
    "    pred = landmark_deltas.copy()\n",
    "    for i in range(5):\n",
    "        pred[:,i,0] = landmark_deltas[:,i,0]*widths + ctr_x\n",
    "        pred[:,i,1] = landmark_deltas[:,i,1]*heights + ctr_y\n",
    "    return pred\n",
    "\n",
    "# This function copied from rcnn module of retinaface-tf2 project: https://github.com/StanislasBertrand/RetinaFace-tf2/blob/master/rcnn/processing/bbox_transform.py\n",
    "def clip_boxes(boxes, im_shape):\n",
    "    # x1 >= 0\n",
    "    boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)\n",
    "    # y1 >= 0\n",
    "    boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)\n",
    "    # x2 < im_shape[1]\n",
    "    boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)\n",
    "    # y2 < im_shape[0]\n",
    "    boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)\n",
    "    return boxes\n",
    "\n",
    "#this function is mainly based on the following code snippet: https://github.com/StanislasBertrand/RetinaFace-tf2/blob/master/rcnn/cython/anchors.pyx\n",
    "def anchors_plane(height, width, stride, base_anchors):\n",
    "    A = base_anchors.shape[0]\n",
    "    c_0_2 = np.tile(np.arange(0, width)[np.newaxis, :, np.newaxis, np.newaxis], (height, 1, A, 1))\n",
    "    c_1_3 = np.tile(np.arange(0, height)[:, np.newaxis, np.newaxis, np.newaxis], (1, width, A, 1))\n",
    "    all_anchors = np.concatenate([c_0_2, c_1_3, c_0_2, c_1_3], axis=-1) * stride + np.tile(base_anchors[np.newaxis, np.newaxis, :, :], (height, width, 1, 1))\n",
    "    return all_anchors\n",
    "\n",
    "#this function is mainly based on the following code snippet: https://github.com/StanislasBertrand/RetinaFace-tf2/blob/master/rcnn/cython/cpu_nms.pyx\n",
    "#Fast R-CNN by Ross Girshick\n",
    "def cpu_nms(dets, threshold):\n",
    "    x1 = dets[:, 0]\n",
    "    y1 = dets[:, 1]\n",
    "    x2 = dets[:, 2]\n",
    "    y2 = dets[:, 3]\n",
    "    scores = dets[:, 4]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    ndets = dets.shape[0]\n",
    "    suppressed = np.zeros((ndets), dtype=int)\n",
    "\n",
    "    keep = []\n",
    "    for _i in range(ndets):\n",
    "        i = order[_i]\n",
    "        if suppressed[i] == 1:\n",
    "            continue\n",
    "        keep.append(i)\n",
    "        ix1 = x1[i]; iy1 = y1[i]; ix2 = x2[i]; iy2 = y2[i]\n",
    "        iarea = areas[i]\n",
    "        for _j in range(_i + 1, ndets):\n",
    "            j = order[_j]\n",
    "            if suppressed[j] == 1:\n",
    "                continue\n",
    "            xx1 = max(ix1, x1[j]); yy1 = max(iy1, y1[j]); xx2 = min(ix2, x2[j]); yy2 = min(iy2, y2[j])\n",
    "            w = max(0.0, xx2 - xx1 + 1); h = max(0.0, yy2 - yy1 + 1)\n",
    "            inter = w * h\n",
    "            ovr = inter / (iarea + areas[j] - inter)\n",
    "            if ovr >= threshold:\n",
    "                suppressed[j] = 1\n",
    "\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import gdown\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "tf_version = int(tf.__version__.split(\".\")[0])\n",
    "\n",
    "if tf_version == 1:\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Input, BatchNormalization, ZeroPadding2D, Conv2D, ReLU, MaxPool2D, Add, UpSampling2D, concatenate, Softmax\n",
    "\n",
    "else:\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Input, BatchNormalization, ZeroPadding2D, Conv2D, ReLU, MaxPool2D, Add, UpSampling2D, concatenate, Softmax\n",
    "\n",
    "def load_weights(model):\n",
    "\n",
    "    home = str(os.getenv('DEEPFACE_HOME', default=Path.home()))\n",
    "\n",
    "    exact_file = home+'/.deepface/weights/retinaface.h5'\n",
    "    #url = 'https://drive.google.com/file/d/1K3Eq2k1b9dpKkucZjPAiCCnNzfCMosK4'\n",
    "    #url = 'https://drive.google.com/uc?id=1K3Eq2k1b9dpKkucZjPAiCCnNzfCMosK4'\n",
    "    url = 'https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5'\n",
    "\n",
    "    #-----------------------------\n",
    "\n",
    "    if not os.path.exists(home+\"/.deepface\"):\n",
    "        os.mkdir(home+\"/.deepface\")\n",
    "        print(\"Directory \",home,\"/.deepface created\")\n",
    "\n",
    "    if not os.path.exists(home+\"/.deepface/weights\"):\n",
    "        os.mkdir(home+\"/.deepface/weights\")\n",
    "        print(\"Directory \",home,\"/.deepface/weights created\")\n",
    "\n",
    "    #-----------------------------\n",
    "\n",
    "    if os.path.isfile(exact_file) != True:\n",
    "        print(\"retinaface.h5 will be downloaded from the url \"+url)\n",
    "        gdown.download(url, exact_file, quiet=False)\n",
    "\n",
    "    #-----------------------------\n",
    "\n",
    "    #gdown should download the pretrained weights here. If it does not still exist, then throw an exception.\n",
    "    if os.path.isfile(exact_file) != True:\n",
    "        raise ValueError(\"Pre-trained weight could not be loaded!\"\n",
    "            +\" You might try to download the pre-trained weights from the url \"+ url\n",
    "            + \" and copy it to the \", exact_file, \"manually.\")\n",
    "\n",
    "    model.load_weights(exact_file)\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_model():\n",
    "\n",
    "    data = Input(dtype=tf.float32, shape=(None, None, 3), name='data')\n",
    "\n",
    "    bn_data = BatchNormalization(epsilon=1.9999999494757503e-05, name='bn_data', trainable=False)(data)\n",
    "\n",
    "    conv0_pad = ZeroPadding2D(padding=tuple([3, 3]))(bn_data)\n",
    "\n",
    "    conv0 = Conv2D(filters = 64, kernel_size = (7, 7), name = 'conv0', strides = [2, 2], padding = 'VALID', use_bias = False)(conv0_pad)\n",
    "\n",
    "    bn0 = BatchNormalization(epsilon=1.9999999494757503e-05, name='bn0', trainable=False)(conv0)\n",
    "\n",
    "    relu0 = ReLU(name='relu0')(bn0)\n",
    "\n",
    "    pooling0_pad = ZeroPadding2D(padding=tuple([1, 1]))(relu0)\n",
    "\n",
    "    pooling0 = MaxPool2D((3, 3), (2, 2), padding='VALID', name='pooling0')(pooling0_pad)\n",
    "\n",
    "    stage1_unit1_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage1_unit1_bn1', trainable=False)(pooling0)\n",
    "\n",
    "    stage1_unit1_relu1 = ReLU(name='stage1_unit1_relu1')(stage1_unit1_bn1)\n",
    "\n",
    "    stage1_unit1_conv1 = Conv2D(filters = 64, kernel_size = (1, 1), name = 'stage1_unit1_conv1', strides = [1, 1], padding = 'VALID', use_bias = False)(stage1_unit1_relu1)\n",
    "\n",
    "    stage1_unit1_sc = Conv2D(filters = 256, kernel_size = (1, 1), name = 'stage1_unit1_sc', strides = [1, 1], padding = 'VALID', use_bias = False)(stage1_unit1_relu1)\n",
    "\n",
    "    stage1_unit1_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage1_unit1_bn2', trainable=False)(stage1_unit1_conv1)\n",
    "\n",
    "    stage1_unit1_relu2 = ReLU(name='stage1_unit1_relu2')(stage1_unit1_bn2)\n",
    "\n",
    "    stage1_unit1_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage1_unit1_relu2)\n",
    "\n",
    "    stage1_unit1_conv2 = Conv2D(filters = 64, kernel_size = (3, 3), name = 'stage1_unit1_conv2', strides = [1, 1], padding = 'VALID', use_bias = False)(stage1_unit1_conv2_pad)\n",
    "\n",
    "    stage1_unit1_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage1_unit1_bn3', trainable=False)(stage1_unit1_conv2)\n",
    "\n",
    "    stage1_unit1_relu3 = ReLU(name='stage1_unit1_relu3')(stage1_unit1_bn3)\n",
    "\n",
    "    stage1_unit1_conv3 = Conv2D(filters = 256, kernel_size = (1, 1), name = 'stage1_unit1_conv3', strides = [1, 1], padding = 'VALID', use_bias = False)(stage1_unit1_relu3)\n",
    "\n",
    "    plus0_v1 = Add()([stage1_unit1_conv3 , stage1_unit1_sc])\n",
    "\n",
    "    stage1_unit2_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage1_unit2_bn1', trainable=False)(plus0_v1)\n",
    "\n",
    "    stage1_unit2_relu1 = ReLU(name='stage1_unit2_relu1')(stage1_unit2_bn1)\n",
    "\n",
    "    stage1_unit2_conv1 = Conv2D(filters = 64, kernel_size = (1, 1), name = 'stage1_unit2_conv1', strides = [1, 1], padding = 'VALID', use_bias = False)(stage1_unit2_relu1)\n",
    "\n",
    "    stage1_unit2_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage1_unit2_bn2', trainable=False)(stage1_unit2_conv1)\n",
    "\n",
    "    stage1_unit2_relu2 = ReLU(name='stage1_unit2_relu2')(stage1_unit2_bn2)\n",
    "\n",
    "    stage1_unit2_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage1_unit2_relu2)\n",
    "\n",
    "    stage1_unit2_conv2 = Conv2D(filters = 64, kernel_size = (3, 3), name = 'stage1_unit2_conv2', strides = [1, 1], padding = 'VALID', use_bias = False)(stage1_unit2_conv2_pad)\n",
    "\n",
    "    stage1_unit2_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage1_unit2_bn3', trainable=False)(stage1_unit2_conv2)\n",
    "\n",
    "    stage1_unit2_relu3 = ReLU(name='stage1_unit2_relu3')(stage1_unit2_bn3)\n",
    "\n",
    "    stage1_unit2_conv3 = Conv2D(filters = 256, kernel_size = (1, 1), name = 'stage1_unit2_conv3', strides = [1, 1], padding = 'VALID', use_bias = False)(stage1_unit2_relu3)\n",
    "\n",
    "    plus1_v2 = Add()([stage1_unit2_conv3 , plus0_v1])\n",
    "\n",
    "    stage1_unit3_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage1_unit3_bn1', trainable=False)(plus1_v2)\n",
    "\n",
    "    stage1_unit3_relu1 = ReLU(name='stage1_unit3_relu1')(stage1_unit3_bn1)\n",
    "\n",
    "    stage1_unit3_conv1 = Conv2D(filters = 64, kernel_size = (1, 1), name = 'stage1_unit3_conv1', strides = [1, 1], padding = 'VALID', use_bias = False)(stage1_unit3_relu1)\n",
    "\n",
    "    stage1_unit3_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage1_unit3_bn2', trainable=False)(stage1_unit3_conv1)\n",
    "\n",
    "    stage1_unit3_relu2 = ReLU(name='stage1_unit3_relu2')(stage1_unit3_bn2)\n",
    "\n",
    "    stage1_unit3_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage1_unit3_relu2)\n",
    "\n",
    "    stage1_unit3_conv2 = Conv2D(filters = 64, kernel_size = (3, 3), name = 'stage1_unit3_conv2', strides = [1, 1], padding = 'VALID', use_bias = False)(stage1_unit3_conv2_pad)\n",
    "\n",
    "    stage1_unit3_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage1_unit3_bn3', trainable=False)(stage1_unit3_conv2)\n",
    "\n",
    "    stage1_unit3_relu3 = ReLU(name='stage1_unit3_relu3')(stage1_unit3_bn3)\n",
    "\n",
    "    stage1_unit3_conv3 = Conv2D(filters = 256, kernel_size = (1, 1), name = 'stage1_unit3_conv3', strides = [1, 1], padding = 'VALID', use_bias = False)(stage1_unit3_relu3)\n",
    "\n",
    "    plus2 = Add()([stage1_unit3_conv3 , plus1_v2])\n",
    "\n",
    "    stage2_unit1_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit1_bn1', trainable=False)(plus2)\n",
    "\n",
    "    stage2_unit1_relu1 = ReLU(name='stage2_unit1_relu1')(stage2_unit1_bn1)\n",
    "\n",
    "    stage2_unit1_conv1 = Conv2D(filters = 128, kernel_size = (1, 1), name = 'stage2_unit1_conv1', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit1_relu1)\n",
    "\n",
    "    stage2_unit1_sc = Conv2D(filters = 512, kernel_size = (1, 1), name = 'stage2_unit1_sc', strides = [2, 2], padding = 'VALID', use_bias = False)(stage2_unit1_relu1)\n",
    "\n",
    "    stage2_unit1_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit1_bn2', trainable=False)(stage2_unit1_conv1)\n",
    "\n",
    "    stage2_unit1_relu2 = ReLU(name='stage2_unit1_relu2')(stage2_unit1_bn2)\n",
    "\n",
    "    stage2_unit1_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage2_unit1_relu2)\n",
    "\n",
    "    stage2_unit1_conv2 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'stage2_unit1_conv2', strides = [2, 2], padding = 'VALID', use_bias = False)(stage2_unit1_conv2_pad)\n",
    "\n",
    "    stage2_unit1_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit1_bn3', trainable=False)(stage2_unit1_conv2)\n",
    "\n",
    "    stage2_unit1_relu3 = ReLU(name='stage2_unit1_relu3')(stage2_unit1_bn3)\n",
    "\n",
    "    stage2_unit1_conv3 = Conv2D(filters = 512, kernel_size = (1, 1), name = 'stage2_unit1_conv3', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit1_relu3)\n",
    "\n",
    "    plus3 = Add()([stage2_unit1_conv3 , stage2_unit1_sc])\n",
    "\n",
    "    stage2_unit2_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit2_bn1', trainable=False)(plus3)\n",
    "\n",
    "    stage2_unit2_relu1 = ReLU(name='stage2_unit2_relu1')(stage2_unit2_bn1)\n",
    "\n",
    "    stage2_unit2_conv1 = Conv2D(filters = 128, kernel_size = (1, 1), name = 'stage2_unit2_conv1', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit2_relu1)\n",
    "\n",
    "    stage2_unit2_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit2_bn2', trainable=False)(stage2_unit2_conv1)\n",
    "\n",
    "    stage2_unit2_relu2 = ReLU(name='stage2_unit2_relu2')(stage2_unit2_bn2)\n",
    "\n",
    "    stage2_unit2_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage2_unit2_relu2)\n",
    "\n",
    "    stage2_unit2_conv2 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'stage2_unit2_conv2', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit2_conv2_pad)\n",
    "\n",
    "    stage2_unit2_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit2_bn3', trainable=False)(stage2_unit2_conv2)\n",
    "\n",
    "    stage2_unit2_relu3 = ReLU(name='stage2_unit2_relu3')(stage2_unit2_bn3)\n",
    "\n",
    "    stage2_unit2_conv3 = Conv2D(filters = 512, kernel_size = (1, 1), name = 'stage2_unit2_conv3', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit2_relu3)\n",
    "\n",
    "    plus4 = Add()([stage2_unit2_conv3 , plus3])\n",
    "\n",
    "    stage2_unit3_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit3_bn1', trainable=False)(plus4)\n",
    "\n",
    "    stage2_unit3_relu1 = ReLU(name='stage2_unit3_relu1')(stage2_unit3_bn1)\n",
    "\n",
    "    stage2_unit3_conv1 = Conv2D(filters = 128, kernel_size = (1, 1), name = 'stage2_unit3_conv1', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit3_relu1)\n",
    "\n",
    "    stage2_unit3_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit3_bn2', trainable=False)(stage2_unit3_conv1)\n",
    "\n",
    "    stage2_unit3_relu2 = ReLU(name='stage2_unit3_relu2')(stage2_unit3_bn2)\n",
    "\n",
    "    stage2_unit3_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage2_unit3_relu2)\n",
    "\n",
    "    stage2_unit3_conv2 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'stage2_unit3_conv2', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit3_conv2_pad)\n",
    "\n",
    "    stage2_unit3_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit3_bn3', trainable=False)(stage2_unit3_conv2)\n",
    "\n",
    "    stage2_unit3_relu3 = ReLU(name='stage2_unit3_relu3')(stage2_unit3_bn3)\n",
    "\n",
    "    stage2_unit3_conv3 = Conv2D(filters = 512, kernel_size = (1, 1), name = 'stage2_unit3_conv3', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit3_relu3)\n",
    "\n",
    "    plus5 = Add()([stage2_unit3_conv3 , plus4])\n",
    "\n",
    "    stage2_unit4_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit4_bn1', trainable=False)(plus5)\n",
    "\n",
    "    stage2_unit4_relu1 = ReLU(name='stage2_unit4_relu1')(stage2_unit4_bn1)\n",
    "\n",
    "    stage2_unit4_conv1 = Conv2D(filters = 128, kernel_size = (1, 1), name = 'stage2_unit4_conv1', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit4_relu1)\n",
    "\n",
    "    stage2_unit4_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit4_bn2', trainable=False)(stage2_unit4_conv1)\n",
    "\n",
    "    stage2_unit4_relu2 = ReLU(name='stage2_unit4_relu2')(stage2_unit4_bn2)\n",
    "\n",
    "    stage2_unit4_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage2_unit4_relu2)\n",
    "\n",
    "    stage2_unit4_conv2 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'stage2_unit4_conv2', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit4_conv2_pad)\n",
    "\n",
    "    stage2_unit4_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name='stage2_unit4_bn3', trainable=False)(stage2_unit4_conv2)\n",
    "\n",
    "    stage2_unit4_relu3 = ReLU(name='stage2_unit4_relu3')(stage2_unit4_bn3)\n",
    "\n",
    "    stage2_unit4_conv3 = Conv2D(filters = 512, kernel_size = (1, 1), name = 'stage2_unit4_conv3', strides = [1, 1], padding = 'VALID', use_bias = False)(stage2_unit4_relu3)\n",
    "\n",
    "    bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name='bn1', trainable=False)(plus15)\n",
    "\n",
    "    relu1 = ReLU(name='relu1')(bn1)\n",
    "\n",
    "    ssh_c3_lateral = Conv2D(filters = 256, kernel_size = (1, 1), name = 'ssh_c3_lateral', strides = [1, 1], padding = 'VALID', use_bias = True)(relu1)\n",
    "\n",
    "    ssh_c3_lateral_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_c3_lateral_bn', trainable=False)(ssh_c3_lateral)\n",
    "\n",
    "    ssh_c3_lateral_relu = ReLU(name='ssh_c3_lateral_relu')(ssh_c3_lateral_bn)\n",
    "\n",
    "    ssh_m3_det_conv1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c3_lateral_relu)\n",
    "\n",
    "    ssh_m3_det_conv1 = Conv2D(filters = 256, kernel_size = (3, 3), name = 'ssh_m3_det_conv1', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m3_det_conv1_pad)\n",
    "\n",
    "    ssh_m3_det_context_conv1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c3_lateral_relu)\n",
    "\n",
    "    ssh_m3_det_context_conv1 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m3_det_context_conv1', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m3_det_context_conv1_pad)\n",
    "\n",
    "    ssh_c3_up = UpSampling2D(size=(2, 2), interpolation=\"nearest\", name=\"ssh_c3_up\")(ssh_c3_lateral_relu)\n",
    "\n",
    "    ssh_m3_det_conv1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m3_det_conv1_bn', trainable=False)(ssh_m3_det_conv1)\n",
    "\n",
    "    ssh_m3_det_context_conv1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m3_det_context_conv1_bn', trainable=False)(ssh_m3_det_context_conv1)\n",
    "\n",
    "    x1_shape = tf.shape(ssh_c3_up)\n",
    "    x2_shape = tf.shape(ssh_c2_lateral_relu)\n",
    "    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\n",
    "    size = [-1, x2_shape[1], x2_shape[2], -1]\n",
    "    crop0 = tf.slice(ssh_c3_up, offsets, size, \"crop0\")\n",
    "\n",
    "    ssh_m3_det_context_conv1_relu = ReLU(name='ssh_m3_det_context_conv1_relu')(ssh_m3_det_context_conv1_bn)\n",
    "\n",
    "    plus0_v2 = Add()([ssh_c2_lateral_relu , crop0])\n",
    "\n",
    "    ssh_m3_det_context_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m3_det_context_conv1_relu)\n",
    "\n",
    "    ssh_m3_det_context_conv2 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m3_det_context_conv2', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m3_det_context_conv2_pad)\n",
    "\n",
    "    ssh_m3_det_context_conv3_1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m3_det_context_conv1_relu)\n",
    "\n",
    "    ssh_m3_det_context_conv3_1 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m3_det_context_conv3_1', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m3_det_context_conv3_1_pad)\n",
    "\n",
    "    ssh_c2_aggr_pad = ZeroPadding2D(padding=tuple([1, 1]))(plus0_v2)\n",
    "\n",
    "    ssh_c2_aggr = Conv2D(filters = 256, kernel_size = (3, 3), name = 'ssh_c2_aggr', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_c2_aggr_pad)\n",
    "\n",
    "    ssh_m3_det_context_conv2_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m3_det_context_conv2_bn', trainable=False)(ssh_m3_det_context_conv2)\n",
    "\n",
    "    ssh_m3_det_context_conv3_1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m3_det_context_conv3_1_bn', trainable=False)(ssh_m3_det_context_conv3_1)\n",
    "\n",
    "    ssh_c2_aggr_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_c2_aggr_bn', trainable=False)(ssh_c2_aggr)\n",
    "\n",
    "    ssh_m3_det_context_conv3_1_relu = ReLU(name='ssh_m3_det_context_conv3_1_relu')(ssh_m3_det_context_conv3_1_bn)\n",
    "\n",
    "    ssh_c2_aggr_relu = ReLU(name='ssh_c2_aggr_relu')(ssh_c2_aggr_bn)\n",
    "\n",
    "    ssh_m3_det_context_conv3_2_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m3_det_context_conv3_1_relu)\n",
    "\n",
    "    ssh_m3_det_context_conv3_2 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m3_det_context_conv3_2', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m3_det_context_conv3_2_pad)\n",
    "\n",
    "    ssh_m2_det_conv1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c2_aggr_relu)\n",
    "\n",
    "    ssh_m2_det_conv1 = Conv2D(filters = 256, kernel_size = (3, 3), name = 'ssh_m2_det_conv1', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m2_det_conv1_pad)\n",
    "\n",
    "    ssh_m2_det_context_conv1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c2_aggr_relu)\n",
    "\n",
    "    ssh_m2_det_context_conv1 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m2_det_context_conv1', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m2_det_context_conv1_pad)\n",
    "\n",
    "    ssh_m2_red_up = UpSampling2D(size=(2, 2), interpolation=\"nearest\", name=\"ssh_m2_red_up\")(ssh_c2_aggr_relu)\n",
    "\n",
    "    ssh_m3_det_context_conv3_2_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m3_det_context_conv3_2_bn', trainable=False)(ssh_m3_det_context_conv3_2)\n",
    "\n",
    "    ssh_m2_det_conv1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m2_det_conv1_bn', trainable=False)(ssh_m2_det_conv1)\n",
    "\n",
    "    ssh_m2_det_context_conv1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m2_det_context_conv1_bn', trainable=False)(ssh_m2_det_context_conv1)\n",
    "\n",
    "    x1_shape = tf.shape(ssh_m2_red_up)\n",
    "    x2_shape = tf.shape(ssh_m1_red_conv_relu)\n",
    "    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\n",
    "    size = [-1, x2_shape[1], x2_shape[2], -1]\n",
    "    crop1 = tf.slice(ssh_m2_red_up, offsets, size, \"crop1\")\n",
    "\n",
    "    ssh_m3_det_concat = concatenate([ssh_m3_det_conv1_bn, ssh_m3_det_context_conv2_bn, ssh_m3_det_context_conv3_2_bn], 3, name='ssh_m3_det_concat')\n",
    "\n",
    "    ssh_m2_det_context_conv1_relu = ReLU(name='ssh_m2_det_context_conv1_relu')(ssh_m2_det_context_conv1_bn)\n",
    "\n",
    "    plus1_v1 = Add()([ssh_m1_red_conv_relu , crop1])\n",
    "\n",
    "    ssh_m3_det_concat_relu = ReLU(name='ssh_m3_det_concat_relu')(ssh_m3_det_concat)\n",
    "\n",
    "    ssh_m2_det_context_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m2_det_context_conv1_relu)\n",
    "\n",
    "    ssh_m2_det_context_conv2 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m2_det_context_conv2', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m2_det_context_conv2_pad)\n",
    "\n",
    "    ssh_m2_det_context_conv3_1_pad  = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m2_det_context_conv1_relu)\n",
    "\n",
    "    ssh_m2_det_context_conv3_1 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m2_det_context_conv3_1', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m2_det_context_conv3_1_pad)\n",
    "\n",
    "    ssh_c1_aggr_pad = ZeroPadding2D(padding=tuple([1, 1]))(plus1_v1)\n",
    "\n",
    "    ssh_c1_aggr = Conv2D(filters = 256, kernel_size = (3, 3), name = 'ssh_c1_aggr', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_c1_aggr_pad)\n",
    "\n",
    "    face_rpn_cls_score_stride32 = Conv2D(filters = 4, kernel_size = (1, 1), name = 'face_rpn_cls_score_stride32', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m3_det_concat_relu)\n",
    "\n",
    "    inter_1 = concatenate([face_rpn_cls_score_stride32[:, :, :, 0], face_rpn_cls_score_stride32[:, :, :, 1]], axis=1)\n",
    "    inter_2 = concatenate([face_rpn_cls_score_stride32[:, :, :, 2], face_rpn_cls_score_stride32[:, :, :, 3]], axis=1)\n",
    "    final = tf.stack([inter_1, inter_2])\n",
    "    face_rpn_cls_score_reshape_stride32 = tf.transpose(final, (1, 2, 3, 0), name=\"face_rpn_cls_score_reshape_stride32\")\n",
    "\n",
    "    face_rpn_bbox_pred_stride32 = Conv2D(filters = 8, kernel_size = (1, 1), name = 'face_rpn_bbox_pred_stride32', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m3_det_concat_relu)\n",
    "\n",
    "    face_rpn_landmark_pred_stride32 = Conv2D(filters = 20, kernel_size = (1, 1), name = 'face_rpn_landmark_pred_stride32', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m3_det_concat_relu)\n",
    "\n",
    "    ssh_m2_det_context_conv2_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m2_det_context_conv2_bn', trainable=False)(ssh_m2_det_context_conv2)\n",
    "\n",
    "    ssh_m2_det_context_conv3_1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m2_det_context_conv3_1_bn', trainable=False)(ssh_m2_det_context_conv3_1)\n",
    "\n",
    "    ssh_c1_aggr_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_c1_aggr_bn', trainable=False)(ssh_c1_aggr)\n",
    "\n",
    "    ssh_m2_det_context_conv3_1_relu = ReLU(name='ssh_m2_det_context_conv3_1_relu')(ssh_m2_det_context_conv3_1_bn)\n",
    "\n",
    "    ssh_c1_aggr_relu = ReLU(name='ssh_c1_aggr_relu')(ssh_c1_aggr_bn)\n",
    "\n",
    "    face_rpn_cls_prob_stride32 = Softmax(name = 'face_rpn_cls_prob_stride32')(face_rpn_cls_score_reshape_stride32)\n",
    "\n",
    "    input_shape = [tf.shape(face_rpn_cls_prob_stride32)[k] for k in range(4)]\n",
    "    sz = tf.dtypes.cast(input_shape[1] / 2, dtype=tf.int32)\n",
    "    inter_1 = face_rpn_cls_prob_stride32[:, 0:sz, :, 0]\n",
    "    inter_2 = face_rpn_cls_prob_stride32[:, 0:sz, :, 1]\n",
    "    inter_3 = face_rpn_cls_prob_stride32[:, sz:, :, 0]\n",
    "    inter_4 = face_rpn_cls_prob_stride32[:, sz:, :, 1]\n",
    "    final = tf.stack([inter_1, inter_3, inter_2, inter_4])\n",
    "    face_rpn_cls_prob_reshape_stride32 = tf.transpose(final, (1, 2, 3, 0), name=\"face_rpn_cls_prob_reshape_stride32\")\n",
    "\n",
    "    ssh_m2_det_context_conv3_2_pad  = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m2_det_context_conv3_1_relu)\n",
    "\n",
    "    ssh_m2_det_context_conv3_2 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m2_det_context_conv3_2', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m2_det_context_conv3_2_pad)\n",
    "\n",
    "    ssh_m1_det_conv1_pad            = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c1_aggr_relu)\n",
    "\n",
    "    ssh_m1_det_conv1 = Conv2D(filters = 256, kernel_size = (3, 3), name = 'ssh_m1_det_conv1', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m1_det_conv1_pad)\n",
    "\n",
    "    ssh_m1_det_context_conv1_pad    = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c1_aggr_relu)\n",
    "\n",
    "    ssh_m1_det_context_conv1 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m1_det_context_conv1', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m1_det_context_conv1_pad)\n",
    "\n",
    "    ssh_m2_det_context_conv3_2_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m2_det_context_conv3_2_bn', trainable=False)(ssh_m2_det_context_conv3_2)\n",
    "\n",
    "    ssh_m1_det_conv1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m1_det_conv1_bn', trainable=False)(ssh_m1_det_conv1)\n",
    "\n",
    "    ssh_m1_det_context_conv1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m1_det_context_conv1_bn', trainable=False)(ssh_m1_det_context_conv1)\n",
    "\n",
    "    ssh_m2_det_concat               = concatenate([ssh_m2_det_conv1_bn, ssh_m2_det_context_conv2_bn, ssh_m2_det_context_conv3_2_bn], 3, name='ssh_m2_det_concat')\n",
    "\n",
    "    ssh_m1_det_context_conv1_relu = ReLU(name='ssh_m1_det_context_conv1_relu')(ssh_m1_det_context_conv1_bn)\n",
    "\n",
    "    ssh_m2_det_concat_relu = ReLU(name='ssh_m2_det_concat_relu')(ssh_m2_det_concat)\n",
    "\n",
    "    ssh_m1_det_context_conv2_pad    = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m1_det_context_conv1_relu)\n",
    "\n",
    "    ssh_m1_det_context_conv2 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m1_det_context_conv2', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m1_det_context_conv2_pad)\n",
    "\n",
    "    ssh_m1_det_context_conv3_1_pad  = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m1_det_context_conv1_relu)\n",
    "\n",
    "    ssh_m1_det_context_conv3_1 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m1_det_context_conv3_1', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m1_det_context_conv3_1_pad)\n",
    "\n",
    "    face_rpn_cls_score_stride16 = Conv2D(filters = 4, kernel_size = (1, 1), name = 'face_rpn_cls_score_stride16', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m2_det_concat_relu)\n",
    "\n",
    "    inter_1 = concatenate([face_rpn_cls_score_stride16[:, :, :, 0], face_rpn_cls_score_stride16[:, :, :, 1]], axis=1)\n",
    "    inter_2 = concatenate([face_rpn_cls_score_stride16[:, :, :, 2], face_rpn_cls_score_stride16[:, :, :, 3]], axis=1)\n",
    "    final = tf.stack([inter_1, inter_2])\n",
    "    face_rpn_cls_score_reshape_stride16 = tf.transpose(final, (1, 2, 3, 0), name=\"face_rpn_cls_score_reshape_stride16\")\n",
    "\n",
    "    face_rpn_bbox_pred_stride16 = Conv2D(filters = 8, kernel_size = (1, 1), name = 'face_rpn_bbox_pred_stride16', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m2_det_concat_relu)\n",
    "\n",
    "    face_rpn_landmark_pred_stride16 = Conv2D(filters = 20, kernel_size = (1, 1), name = 'face_rpn_landmark_pred_stride16', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m2_det_concat_relu)\n",
    "\n",
    "    ssh_m1_det_context_conv2_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m1_det_context_conv2_bn', trainable=False)(ssh_m1_det_context_conv2)\n",
    "\n",
    "    ssh_m1_det_context_conv3_1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m1_det_context_conv3_1_bn', trainable=False)(ssh_m1_det_context_conv3_1)\n",
    "\n",
    "    ssh_m1_det_context_conv3_1_relu = ReLU(name='ssh_m1_det_context_conv3_1_relu')(ssh_m1_det_context_conv3_1_bn)\n",
    "\n",
    "    face_rpn_cls_prob_stride16      = Softmax(name = 'face_rpn_cls_prob_stride16')(face_rpn_cls_score_reshape_stride16)\n",
    "\n",
    "    input_shape = [tf.shape(face_rpn_cls_prob_stride16)[k] for k in range(4)]\n",
    "    sz = tf.dtypes.cast(input_shape[1] / 2, dtype=tf.int32)\n",
    "    inter_1 = face_rpn_cls_prob_stride16[:, 0:sz, :, 0]\n",
    "    inter_2 = face_rpn_cls_prob_stride16[:, 0:sz, :, 1]\n",
    "    inter_3 = face_rpn_cls_prob_stride16[:, sz:, :, 0]\n",
    "    inter_4 = face_rpn_cls_prob_stride16[:, sz:, :, 1]\n",
    "    final = tf.stack([inter_1, inter_3, inter_2, inter_4])\n",
    "    face_rpn_cls_prob_reshape_stride16 = tf.transpose(final, (1, 2, 3, 0), name=\"face_rpn_cls_prob_reshape_stride16\")\n",
    "\n",
    "    ssh_m1_det_context_conv3_2_pad  = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m1_det_context_conv3_1_relu)\n",
    "\n",
    "    ssh_m1_det_context_conv3_2 = Conv2D(filters = 128, kernel_size = (3, 3), name = 'ssh_m1_det_context_conv3_2', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m1_det_context_conv3_2_pad)\n",
    "\n",
    "    ssh_m1_det_context_conv3_2_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name='ssh_m1_det_context_conv3_2_bn', trainable=False)(ssh_m1_det_context_conv3_2)\n",
    "\n",
    "    ssh_m1_det_concat               = concatenate([ssh_m1_det_conv1_bn, ssh_m1_det_context_conv2_bn, ssh_m1_det_context_conv3_2_bn], 3, name='ssh_m1_det_concat')\n",
    "\n",
    "    ssh_m1_det_concat_relu = ReLU(name='ssh_m1_det_concat_relu')(ssh_m1_det_concat)\n",
    "    face_rpn_cls_score_stride8 = Conv2D(filters = 4, kernel_size = (1, 1), name = 'face_rpn_cls_score_stride8', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m1_det_concat_relu)\n",
    "\n",
    "    inter_1 = concatenate([face_rpn_cls_score_stride8[:, :, :, 0], face_rpn_cls_score_stride8[:, :, :, 1]], axis=1)\n",
    "    inter_2 = concatenate([face_rpn_cls_score_stride8[:, :, :, 2], face_rpn_cls_score_stride8[:, :, :, 3]], axis=1)\n",
    "    final = tf.stack([inter_1, inter_2])\n",
    "    face_rpn_cls_score_reshape_stride8 = tf.transpose(final, (1, 2, 3, 0), name=\"face_rpn_cls_score_reshape_stride8\")\n",
    "\n",
    "    face_rpn_bbox_pred_stride8 = Conv2D(filters = 8, kernel_size = (1, 1), name = 'face_rpn_bbox_pred_stride8', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m1_det_concat_relu)\n",
    "\n",
    "    face_rpn_landmark_pred_stride8 = Conv2D(filters = 20, kernel_size = (1, 1), name = 'face_rpn_landmark_pred_stride8', strides = [1, 1], padding = 'VALID', use_bias = True)(ssh_m1_det_concat_relu)\n",
    "\n",
    "    face_rpn_cls_prob_stride8       = Softmax(name = 'face_rpn_cls_prob_stride8')(face_rpn_cls_score_reshape_stride8)\n",
    "\n",
    "    input_shape = [tf.shape(face_rpn_cls_prob_stride8)[k] for k in range(4)]\n",
    "    sz = tf.dtypes.cast(input_shape[1] / 2, dtype=tf.int32)\n",
    "    inter_1 = face_rpn_cls_prob_stride8[:, 0:sz, :, 0]\n",
    "    inter_2 = face_rpn_cls_prob_stride8[:, 0:sz, :, 1]\n",
    "    inter_3 = face_rpn_cls_prob_stride8[:, sz:, :, 0]\n",
    "    inter_4 = face_rpn_cls_prob_stride8[:, sz:, :, 1]\n",
    "    final = tf.stack([inter_1, inter_3, inter_2, inter_4])\n",
    "    face_rpn_cls_prob_reshape_stride8 = tf.transpose(final, (1, 2, 3, 0), name=\"face_rpn_cls_prob_reshape_stride8\")\n",
    "\n",
    "    model = Model(inputs=data,\n",
    "                    outputs=[face_rpn_cls_prob_reshape_stride32,\n",
    "                                                   face_rpn_bbox_pred_stride32,\n",
    "                                                   face_rpn_landmark_pred_stride32,\n",
    "                                                   face_rpn_cls_prob_reshape_stride16,\n",
    "                                                   face_rpn_bbox_pred_stride16,\n",
    "                                                   face_rpn_landmark_pred_stride16,\n",
    "                                                   face_rpn_cls_prob_reshape_stride8,\n",
    "                                                   face_rpn_bbox_pred_stride8,\n",
    "                                                   face_rpn_landmark_pred_stride8\n",
    "                                                   ])\n",
    "    model = load_weights(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#---------------------------\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "#---------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "tf_version = int(tf.__version__.split(\".\")[0])\n",
    "\n",
    "if tf_version == 2:\n",
    "    import logging\n",
    "    tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "#---------------------------\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    global model #singleton design pattern\n",
    "    \n",
    "    if not \"model\" in globals():\n",
    "        \n",
    "        model = tf.function(\n",
    "            build_model(),\n",
    "            input_signature=(tf.TensorSpec(shape=[None, None, None, 3], dtype=np.float32),)\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_image(img_path):\n",
    "    if type(img_path) == str:  # Load from file path\n",
    "        if not os.path.isfile(img_path):\n",
    "            raise ValueError(\"Input image file path (\", img_path, \") does not exist.\")\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "    elif isinstance(img_path, np.ndarray):  # Use given NumPy array\n",
    "        img = img_path.copy()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid image input. Only file paths or a NumPy array accepted.\")\n",
    "\n",
    "    # Validate image shape\n",
    "    if len(img.shape) != 3 or np.prod(img.shape) == 0:\n",
    "        raise ValueError(\"Input image needs to have 3 channels at must not be empty.\")\n",
    "\n",
    "    return img\n",
    "\n",
    "def detect_faces(img_path, threshold=0.9, model = None, allow_upscaling = True):\n",
    "    resp = {}\n",
    "\n",
    "    img = get_image(img_path)\n",
    "\n",
    "    #---------------------------\n",
    "\n",
    "    if model is None:\n",
    "        model = build_model()\n",
    "\n",
    "    #---------------------------\n",
    "\n",
    "    nms_threshold = 0.4; decay4=0.5\n",
    "\n",
    "    _feat_stride_fpn = [32, 16, 8]\n",
    "\n",
    "    _anchors_fpn = {\n",
    "        'stride32': np.array([[-248., -248.,  263.,  263.], [-120., -120.,  135.,  135.]], dtype=np.float32),\n",
    "        'stride16': np.array([[-56., -56.,  71.,  71.], [-24., -24.,  39.,  39.]], dtype=np.float32),\n",
    "        'stride8': np.array([[-8., -8., 23., 23.], [ 0.,  0., 15., 15.]], dtype=np.float32)\n",
    "    }\n",
    "\n",
    "    _num_anchors = {'stride32': 2, 'stride16': 2, 'stride8': 2}\n",
    "\n",
    "    #---------------------------\n",
    "\n",
    "    proposals_list = []\n",
    "    scores_list = []\n",
    "    landmarks_list = []\n",
    "    im_tensor, im_info, im_scale = preprocess_image(img, allow_upscaling)\n",
    "    net_out = model(im_tensor)\n",
    "    net_out = [elt.numpy() for elt in net_out]\n",
    "    sym_idx = 0\n",
    "\n",
    "    for _idx, s in enumerate(_feat_stride_fpn):\n",
    "        _key = 'stride%s'%s\n",
    "        scores = net_out[sym_idx]\n",
    "        scores = scores[:, :, :, _num_anchors['stride%s'%s]:]\n",
    "\n",
    "        bbox_deltas = net_out[sym_idx + 1]\n",
    "        height, width = bbox_deltas.shape[1], bbox_deltas.shape[2]\n",
    "\n",
    "        A = _num_anchors['stride%s'%s]\n",
    "        K = height * width\n",
    "        anchors_fpn = _anchors_fpn['stride%s'%s]\n",
    "        anchors = anchors_plane(height, width, s, anchors_fpn)\n",
    "        anchors = anchors.reshape((K * A, 4))\n",
    "        scores = scores.reshape((-1, 1))\n",
    "\n",
    "        bbox_stds = [1.0, 1.0, 1.0, 1.0]\n",
    "        bbox_deltas = bbox_deltas\n",
    "        bbox_pred_len = bbox_deltas.shape[3]//A\n",
    "        bbox_deltas = bbox_deltas.reshape((-1, bbox_pred_len))\n",
    "        bbox_deltas[:, 0::4] = bbox_deltas[:,0::4] * bbox_stds[0]\n",
    "        bbox_deltas[:, 1::4] = bbox_deltas[:,1::4] * bbox_stds[1]\n",
    "        bbox_deltas[:, 2::4] = bbox_deltas[:,2::4] * bbox_stds[2]\n",
    "        bbox_deltas[:, 3::4] = bbox_deltas[:,3::4] * bbox_stds[3]\n",
    "        proposals = bbox_pred(anchors, bbox_deltas)\n",
    "\n",
    "        proposals = clip_boxes(proposals, im_info[:2])\n",
    "\n",
    "        if s==4 and decay4<1.0:\n",
    "            scores *= decay4\n",
    "\n",
    "        scores_ravel = scores.ravel()\n",
    "        order = np.where(scores_ravel>=threshold)[0]\n",
    "        proposals = proposals[order, :]\n",
    "        scores = scores[order]\n",
    "\n",
    "        proposals[:, 0:4] /= im_scale\n",
    "        proposals_list.append(proposals)\n",
    "        scores_list.append(scores)\n",
    "\n",
    "        landmark_deltas = net_out[sym_idx + 2]\n",
    "        landmark_pred_len = landmark_deltas.shape[3]//A\n",
    "        landmark_deltas = landmark_deltas.reshape((-1, 5, landmark_pred_len//5))\n",
    "        landmarks = landmark_pred(anchors, landmark_deltas)\n",
    "        landmarks = landmarks[order, :]\n",
    "\n",
    "        landmarks[:, :, 0:2] /= im_scale\n",
    "        landmarks_list.append(landmarks)\n",
    "        sym_idx += 3\n",
    "\n",
    "    proposals = np.vstack(proposals_list)\n",
    "    \n",
    "    if proposals.shape[0]==0:\n",
    "        return resp\n",
    "\n",
    "    scores = np.vstack(scores_list)\n",
    "    scores_ravel = scores.ravel()\n",
    "    order = scores_ravel.argsort()[::-1]\n",
    "\n",
    "    proposals = proposals[order, :]\n",
    "    scores = scores[order]\n",
    "    landmarks = np.vstack(landmarks_list)\n",
    "    landmarks = landmarks[order].astype(np.float32, copy=False)\n",
    "\n",
    "    pre_det = np.hstack((proposals[:,0:4], scores)).astype(np.float32, copy=False)\n",
    "\n",
    "    #nms = cpu_nms_wrapper(nms_threshold)\n",
    "    #keep = nms(pre_det)\n",
    "    keep = cpu_nms(pre_det, nms_threshold)\n",
    "\n",
    "    det = np.hstack( (pre_det, proposals[:,4:]) )\n",
    "    det = det[keep, :]\n",
    "    landmarks = landmarks[keep]\n",
    "\n",
    "    for idx, face in enumerate(det):\n",
    "\n",
    "        label = 'face_'+str(idx+1)\n",
    "        resp[label] = {}\n",
    "        resp[label][\"score\"] = face[4]\n",
    "\n",
    "        resp[label][\"facial_area\"] = list(face[0:4].astype(int))\n",
    "\n",
    "        resp[label][\"landmarks\"] = {}\n",
    "        resp[label][\"landmarks\"][\"right_eye\"] = list(landmarks[idx][0])\n",
    "        resp[label][\"landmarks\"][\"left_eye\"] = list(landmarks[idx][1])\n",
    "        resp[label][\"landmarks\"][\"nose\"] = list(landmarks[idx][2])\n",
    "        resp[label][\"landmarks\"][\"mouth_right\"] = list(landmarks[idx][3])\n",
    "        resp[label][\"landmarks\"][\"mouth_left\"] = list(landmarks[idx][4])\n",
    "\n",
    "    return resp\n",
    "\n",
    "def extract_faces(img_path, threshold=0.9, model = None, align = True, allow_upscaling = True):\n",
    "\n",
    "    resp = []\n",
    "\n",
    "    #---------------------------\n",
    "\n",
    "    img = get_image(img_path)\n",
    "\n",
    "    #---------------------------\n",
    "\n",
    "    obj = detect_faces(img_path = img, threshold = threshold, model = model, allow_upscaling = allow_upscaling)\n",
    "\n",
    "    if type(obj) == dict:\n",
    "        for key in obj:\n",
    "            identity = obj[key]\n",
    "\n",
    "            facial_area = identity[\"facial_area\"]\n",
    "            facial_img = img[facial_area[1]: facial_area[3], facial_area[0]: facial_area[2]]\n",
    "\n",
    "            if align == True:\n",
    "                landmarks = identity[\"landmarks\"]\n",
    "                left_eye = landmarks[\"left_eye\"]\n",
    "                right_eye = landmarks[\"right_eye\"]\n",
    "                nose = landmarks[\"nose\"]\n",
    "                mouth_right = landmarks[\"mouth_right\"]\n",
    "                mouth_left = landmarks[\"mouth_left\"]\n",
    "\n",
    "                facial_img = alignment_procedure(facial_img, right_eye, left_eye, nose)\n",
    "\n",
    "            resp.append(facial_img[:, :, ::-1])\n",
    "    #elif type(obj) == tuple:\n",
    "\n",
    "    return resp"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

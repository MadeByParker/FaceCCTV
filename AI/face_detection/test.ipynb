{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: labelme in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (5.0.4)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (2.10.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (3.2.2)\n",
      "Requirement already satisfied: albumentations in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (1.3.0)\n",
      "Requirement already satisfied: split-folders in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (0.5.1)\n",
      "Requirement already satisfied: imutils in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (0.5.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (1.1.3)\n",
      "Requirement already satisfied: keras in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (2.10.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.5.3-cp39-cp39-win_amd64.whl (10.9 MB)\n",
      "     ---------------------------------------- 10.9/10.9 MB 8.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: imgviz>=0.11 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from labelme) (1.5.1)\n",
      "Requirement already satisfied: natsort>=7.1.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from labelme) (8.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from labelme) (1.23.4)\n",
      "Requirement already satisfied: Pillow>=2.8 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from labelme) (9.3.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from labelme) (6.0)\n",
      "Requirement already satisfied: qtpy!=1.11.2 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from labelme) (2.2.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from labelme) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from labelme) (0.4.6)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: qudida>=0.0.4 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from albumentations) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.1.0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from scikit-image>=0.16.1->albumentations) (2.8.7)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from scikit-image>=0.16.1->albumentations) (2022.10.10)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from scikit-image>=0.16.1->albumentations) (2.22.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.5.3 pytz-2022.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Harry Parker\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user labelme tensorflow tensorflow-gpu opencv-python matplotlib albumentations split-folders imutils scikit-learn keras pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Generator\n",
    "from models import Discriminator\n",
    "from dataset import arrange_data\n",
    "from dataset import WIDER\n",
    "from tools import show_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m     size \u001b[39m=\u001b[39m wh[:, \u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m wh[:, \u001b[39m1\u001b[39m]\n\u001b[0;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m size \u001b[39m/\u001b[39m (sizea \u001b[39m+\u001b[39m sizeb \u001b[39m-\u001b[39m size)\n\u001b[1;32m---> 43\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mWIDER\u001b[39;00m(Dataset):\n\u001b[0;32m     45\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, base, path, bbxs, high_resolution\u001b[39m=\u001b[39m(\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m)):\n\u001b[0;32m     46\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase \u001b[39m=\u001b[39m base\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Transforms for low resolution images and high resolution images\n",
    "def transform_hl_pair(hr_height, hr_width):\n",
    "\n",
    "    lr_transforms = [transforms.Resize((hr_height // 4, hr_width // 4), Image.BICUBIC),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "\n",
    "    hr_transforms = [transforms.Resize((hr_height, hr_width), Image.BICUBIC),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "\n",
    "    return transforms.Compose(lr_transforms), transforms.Compose(hr_transforms)\n",
    "\n",
    "\n",
    "def arrange_data(path):\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    data = [x.strip() for x in data]\n",
    "    flags = []\n",
    "    for (i, x) in enumerate(data):\n",
    "        if (x.endswith('.jpg')):\n",
    "            flags.append(i)\n",
    "        else:\n",
    "            data[i] = [int(loc) for loc in x.split(' ')[:4]]\n",
    "\n",
    "    path = np.array(data)[flags].tolist()\n",
    "    bbxs = [x[2:] for x in np.split(data, flags[1:])]\n",
    "    return path, bbxs\n",
    "\n",
    "\n",
    "def iou(a, b):\n",
    "    sizea = (a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1])\n",
    "    sizeb = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    tl = np.maximum(a[:, :2], b[:2])\n",
    "    br = np.minimum(a[:, 2:], b[2:])\n",
    "    wh = np.maximum(br - tl, 0)\n",
    "    size = wh[:, 0] * wh[:, 1]\n",
    "    return size / (sizea + sizeb - size)\n",
    "\n",
    "\n",
    "class WIDER(Dataset):\n",
    "\n",
    "    def __init__(self, base, path, bbxs, high_resolution=(128, 128)):\n",
    "        self.base = base\n",
    "        self.path = path\n",
    "        self.bbxs = bbxs\n",
    "        self.lr, self.hr = transform_hl_pair(*high_resolution)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(join(self.base, self.path[idx]))\n",
    "        bbxs = np.vstack(self.bbxs[idx])\n",
    "        # random select one face\n",
    "        idx = np.random.randint(0, len(bbxs), 1)\n",
    "        bbxs[:, 2:] += bbxs[:, 0:2]\n",
    "\n",
    "        bbx = bbxs[idx, :].squeeze()\n",
    "        true = img.crop(bbx)\n",
    "        # random crop a fix-sized background patch\n",
    "        x, y = np.random.randint(0, min(img.size) - 128, 2)\n",
    "        bg = [x, y, x + 128, y + 128]\n",
    "        if np.all(iou(bbxs, bg) < 0.5):\n",
    "            false = img.crop(bg)\n",
    "        else:\n",
    "            false = Image.fromarray(np.random.randint(0, 256, size=(128, 128, 3)).astype('uint8'))\n",
    "            print(\"use random noise.\")\n",
    "        return {\"lr_face\": self.lr(true), \"lr_background\": self.lr(false),\n",
    "                \"hr_face\": self.hr(true), \"hr_background\": self.hr(false)}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_path = \"./WIDER/WIDER_train/images/\"\n",
    "    path, bbxs = arrange_data()\n",
    "    wider = WIDER(train_path, path, bbxs)\n",
    "    result = wider[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torchvision import utils\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Configure loss\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "bce = nn.BCELoss(reduction='none')\n",
    "\n",
    "\n",
    "def G_loss(g1, g2, pixel_label, d, adv_cls_label, trade_off):\n",
    "    pixel_loss = mse(g1, pixel_label) + mse(g2, pixel_label)\n",
    "    adv_cls_loss = torch.sum(bce(d, adv_cls_label) * trade_off)\n",
    "    return pixel_loss + adv_cls_loss\n",
    "\n",
    "def D_loss(d, adv_cls_label):\n",
    "    return torch.sum(bce(d, adv_cls_label))\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, .0, .1)\n",
    "        torch.nn.init.constant_(m.bias.data, .0)\n",
    "\n",
    "def show_grid(x, figsize=(10, 20), nrow=8):\n",
    "    nums, _, length, width = x.size()\n",
    "    img_grid = utils.make_grid(x, normalize=True, scale_each=True, nrow=nrow)\n",
    "    r = math.ceil(nums / nrow)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(np.transpose(img_grid.detach().cpu().numpy(), (1, 2, 0)))\n",
    "    plt.gca().xaxis.set_ticks_position(\"top\")\n",
    "    plt.xticks(np.arange(0, (nrow+1) * (width+2), width+2), np.arange(nrow))\n",
    "    plt.yticks(np.arange(0, (r+1) * (length+2), (length+2)), np.arange(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./WIDER/WIDER_train/images/\"\n",
    "val_path = \"./WIDER/WIDER_val/images/\"\n",
    "anno_path = \"./WIDER/wider_face_split/wider_face_val_bbx_gt.txt\"\n",
    "\n",
    "path, bbxs = arrange_data(anno_path)\n",
    "wider = WIDER(val_path, path, bbxs)\n",
    "dataloader = DataLoader(wider, batch_size=16, shuffle=True, num_workers=8)\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = images.batch(4).as_numpy_iterator()\n",
    "\n",
    "plot_images = image_generator.next()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for i, image in enumerate(plot_images):\n",
    "    axes[i].imshow(image)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_images), len(test_images), len(val_images), len(train_labels), len(val_labels)\n",
    "\n",
    "train = tf.data.Dataset.zip((train_images, train_labels))\n",
    "train = train.shuffle(5000)\n",
    "train = train.batch(64)\n",
    "train = train.prefetch(8)\n",
    "\n",
    "##test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "#test = test.shuffle(1500)\n",
    "#test = test.batch(64)\n",
    "#test = test.prefetch(8)\n",
    "\n",
    "val = tf.data.Dataset.zip((val_images, val_labels))\n",
    "val = val.shuffle(1000)\n",
    "val = val.batch(64)\n",
    "val = val.prefetch(8)\n",
    "\n",
    "train.as_numpy_iterator().next()[1]\n",
    "\n",
    "data_samples = train.as_numpy_iterator().next()\n",
    "\n",
    "res = data_samples.next()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for i in range(4):\n",
    "    samples_image = res[0][i]\n",
    "    sample_coords = res[1][1][i]\n",
    "\n",
    "    cv2.rectangle(samples_image, \n",
    "                  tuple(np.multiply(sample_coords[:2], [120, 120]).astype(int)),\n",
    "                  tuple(np.multiply(sample_coords[2:], [120, 120]).astype(int)),\n",
    "                  (255, 0, 0), 2)\n",
    "\n",
    "axes[i].imshow(samples_image)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from keras.applications import VGG16\n",
    "\n",
    "vgg = VGG16(include_top=False)\n",
    "\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building classifer \n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8*baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),\n",
    "                     input_shape=(IMAGE_H, IMAGE_W, 3),activation=LeakyReLU(alpha=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(8*baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(4 * baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(4 * baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))  \n",
    "\n",
    "    model.add(Conv2D(2 * baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(2 * baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))  \n",
    "    \n",
    "    model.add(Conv2D(2 * baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Dropout(0.1))  \n",
    "   \n",
    "    model.add(Conv2D(baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(BOX * (4 + 1), (1,1), strides=(1,1)))\n",
    "    model.add(Reshape((GRID_H, GRID_W,BOX, 4 + 1)))\n",
    "\n",
    "    return model\n",
    "\n",
    "faceDetectionModel = build_model()\n",
    "faceDetectionModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.as_numpy_iterator().next()\n",
    "X.shape\n",
    "\n",
    "classes, coords = faceDetectionModel.predict(X)\n",
    "\n",
    "classes, coords\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceDetectionModel.compile(loss=custom_loss, optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    print(\"Mask\",np.shape(mask_shape))\n",
    "\n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    print(\"cell_x\",np.shape(cell_x))\n",
    "    cell_y = cell_x\n",
    "    print(\"cell_y\",np.shape(cell_y))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
    "    print(\"cell_grid\",np.shape(cell_grid))\n",
    "\n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    print(\"coord_mask\",np.shape(coord_mask))\n",
    "    \n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])    \n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    true_box_xy = y_true[..., 0:2] \n",
    "    true_box_wh = y_true[..., 2:4] \n",
    "    true_box_conf = y_true[..., 4]\n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    \n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES),\n",
    "                   lambda: [true_box_xy + (0.5) * no_boxes_mask, \n",
    "                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2])* no_boxes_mask, tf.ones_like(coord_mask)],\n",
    "                   lambda: [true_box_xy, true_box_wh, coord_mask])\n",
    "    \n",
    " \n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    # nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "\n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(tf.sqrt(true_box_wh)-tf.sqrt(pred_box_wh))     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf))\n",
    "    loss = loss_xy + loss_wh + loss_conf\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = len(train_images)\n",
    "lr_decay = (1./0.75-1)/batches_per_epoch\n",
    "\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=lr_decay)\n",
    "\n",
    "def localisation_loss(y_true, yhat):\n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2]))\n",
    "\n",
    "    h_true = y_true[:,3] - y_true[:,1]\n",
    "    w_true = y_true[:,2] - y_true[:,0]\n",
    "\n",
    "    h_pred = yhat[:,3] - yhat[:,1]\n",
    "    w_pred = yhat[:,2] - yhat[:,0]\n",
    "\n",
    "    delta_size = tf.reduce_sum(tf.square(tf.sqrth_true - w_true) + tf.square(h_pred - w_pred))\n",
    "\n",
    "    return delta_coord + delta_size\n",
    "\n",
    "classloss = tf.keras.losses.BinaryCrossentropy()\n",
    "regloss = localisation_loss\n",
    "\n",
    "localisation_loss(y[1], coords)\n",
    "\n",
    "classloss(y[0], classes)\n",
    "\n",
    "regloss(y[1], coords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetection(Model):\n",
    "      def __init__(self, facecctv, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = facecctv\n",
    "\n",
    "      def compile(self, optimiser, classloss, localisationloss, **kwargs):\n",
    "          super().compile(**kwargs)\n",
    "          self.classloss = classloss\n",
    "          self.localisationloss = localisationloss\n",
    "          self.optimiser = optimiser\n",
    "      \n",
    "      def train_step(self, batch, **kwargs):\n",
    "          \n",
    "            X, y = batch\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                  classes, coords = self.model(X, training=True)\n",
    "\n",
    "                  batch_class_loss = self.classloss(y[0], classes)\n",
    "\n",
    "                  batch_localisation_loss = self.localisationloss(tf.cast(y[1], tf.float32), coords)\n",
    "\n",
    "                  total_loss = 0.5*batch_class_loss + batch_localisation_loss\n",
    "\n",
    "                  gradients = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "\n",
    "            optimiser.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "\n",
    "            return {\"class_loss\": batch_class_loss, \"localisation_loss\": batch_localisation_loss, \"total_loss\": total_loss}\n",
    "      \n",
    "      def test_step(self, batch, **kwargs):\n",
    "            X, y = batch\n",
    "\n",
    "            classes, coords = self.model(X, training=False)\n",
    "\n",
    "            batch_class_loss = self.classloss(y[0], classes)\n",
    "\n",
    "            batch_localisation_loss = self.localisationloss(tf.cast(y[1], tf.float32), coords)\n",
    "\n",
    "            total_loss = 0.5*batch_class_loss + batch_localisation_loss\n",
    "\n",
    "            return {\"class_loss\": batch_class_loss, \"localisation_loss\": batch_localisation_loss, \"total_loss\": total_loss}\n",
    "          \n",
    "      def call(self, X, **kwargs):\n",
    "            return self.model(X, **kwargs)\n",
    "      \n",
    "model = FaceDetection(faceDetectionModel)\n",
    "model.compile(optimiser, classloss, regloss)\n",
    "\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir, histogram_freq = 1)\n",
    "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])\n",
    "\n",
    "hist.history\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(20, 5))\n",
    "\n",
    "axes[0].plot(hist.history['total_loss'], color='teal', label='total_loss')\n",
    "axes[0].plot(hist.history['val_total_loss'], color='orange', label='val_total_loss')\n",
    "axes[0].set_title('Total Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(hist.history['class_loss'], color='teal', label='class_loss')\n",
    "axes[1].plot(hist.history['val_class_loss'], color='orange', label='val_class_loss')\n",
    "axes[1].set_title('Classification Loss')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(hist.history['localisation_loss'], color='teal', label='localisation_loss')\n",
    "axes[2].plot(hist.history['val_localisation_loss'], color='orange', label='val_localisation_loss')\n",
    "axes[2].set_title('Localisation Loss')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "i, x, y = GenerateBatch(i,500)\n",
    "print(i)\n",
    "x_train, x_test, y_train ,y_test = train_test_split(x, y, test_size=0.2, random_state=50)\n",
    "print(np.shape(y_train))\n",
    "y_train = np.reshape(y_train,(len(x_train),13, 13, BOX, 5))\n",
    "print(np.shape(y_train))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceDetectionModel.fit(x_train, y_train, epochs=50, batch_size=BATCH_SIZE, validation_data=(x_test,y_test), verbose=1)\n",
    "faceDetectionModel.save_weights(\"faceDetectionModel.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.exp(0.5))\n",
    "print(np.log(np.exp(0.05)))\n",
    "     \n",
    "\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "_, tempx, ty = GenerateBatch(0,1000)\n",
    "img = tempx[0]\n",
    "true_box_wh = ty[..., 2:4]\n",
    "print(np.shape(true_box_wh))\n",
    "i = ty[0].reshape((GRID_H * GRID_W,5))[67]\n",
    "print(i)\n",
    "Nx,Ny, Nw, Nh = ReAdjustCord(i[0]*(8/GRID_W),i[1]*(5/GRID_H), i[2], i[3],img)\n",
    "cv2.rectangle(img, (int(Nx),int(Ny)), (int(Nw)+int(Nx),int(Nh)+int(Ny)), (255,0,0)) \n",
    "cv2.imshow(img)\n",
    "print(Nx,Ny, Nw, Nh)\n",
    "tempy = model.predict(tempx)\n",
    "i = tempy[0].reshape((GRID_H * GRID_W,5))[67]\n",
    "Nx,Ny, Nw, Nh = sigmoid(i[0]),sigmoid(i[1]), np.exp(i[2]), np.exp(i[3])\n",
    "print(Nx,Ny, Nw, Nh)\n",
    "Nx,Ny, Nw, Nh = ReAdjustCord(Nx*(8/GRID_W),Ny*(5/GRID_H), Nw, Nh,img)\n",
    "print(Nx,Ny, Nw, Nh)\n",
    "cv2.rectangle(img, (int(Nx),int(Ny)), (int(Nw)+int(Nx),int(Nh)+int(Ny)), (255,0,0)) \n",
    "cv2.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(GRID_H * GRID_W):\n",
    "  tt = ty[0].reshape((GRID_H * GRID_W,5))[i]\n",
    "  if(tt[4] > 0.5):\n",
    "    print(tt)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tempx, ty = GenerateBatch(0,1000)\n",
    "tempy = model.predict(tempx)\n",
    "img = tempx[0]\n",
    "print(np.shape(tempy[0]))\n",
    "for idx,i in enumerate(ty[0].reshape((9,5))):\n",
    "    if(float(i[4]) > 0.5):\n",
    "      print(\"ssss\",i,idx)\n",
    "      Nx,Ny, Nw, Nh = sigmoid(i[0]),sigmoid(i[1]), i[2], i[3]\n",
    "      print(Nx,Ny, Nw, Nh)\n",
    "      Nx,Ny, Nw, Nh = ReAdjustCord(i[0],i[1], i[2], i[3],img)\n",
    "      print(Nx,Ny, Nw, Nh)\n",
    "      cv2.rectangle(img, (int(Nx),int(Ny)), (int(Nw)+int(Nx),int(Nh)+int(Ny)), (255,0,0)) \n",
    "      cv2.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x)\n",
    "predicted = np.reshape(predicted,(1,3*3,5))\n",
    "for i in predicted[0]:\n",
    "      if(float(i[0]) > 0.5):\n",
    "            print(i)\n",
    "print(np.sum(predicted,axis = 1))\n",
    "print(np.sum(np.reshape(y,(1,3*3,5)),axis = 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_nupmy_iterator().next()\n",
    "test_samples = test_data.next()\n",
    "yhat = faceDetectionModel.predict(test_samples[0])\n",
    "\n",
    "fig, axes = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for i in range(4):\n",
    "      sample_image = test_samples[0][i]\n",
    "      sample_coords = yhat[1][i]\n",
    "\n",
    "      if yhat[0][i] > 0.9:\n",
    "            cv2.rectangle(sample_image,\n",
    "                        tuple(np.multiply(sample_coords[:2], 120).astype(int)),\n",
    "                        tuple(np.multiply(sample_coords[2:], 120).astype(int)),\n",
    "                        (255, 0, 0), 2)\n",
    "            \n",
    "      axes[i].imshow(sample_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "faceDetectionModel.save('faceDetectionModel.h5')\n",
    "faceDetectionModel = load_model('faceDetectionModel.h5', custom_objects={'localisation_loss': localisation_loss})\n",
    "\n",
    "faceDetectionModel.summary()\n",
    "\n",
    "def detect_face(image, model):\n",
    "      image = cv2.resize(image, (120, 120))\n",
    "      image = image.astype('float32')/255.\n",
    "      image = np.expand_dims(image, axis=0)\n",
    "      classes, coords = model.predict(image)\n",
    "      if classes[0][0] > 0.9:\n",
    "            return coords[0]\n",
    "      else:\n",
    "            return None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fdfab0a92e8e4f102adc2e2599460964d49375dabd66f1360fe0d1bdaf9560b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

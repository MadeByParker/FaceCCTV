{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (2.11.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (4.7.0.68)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: imutils in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (0.5.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: keras in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (2.11.0)\n",
      "Requirement already satisfied: ssd in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (1.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.24.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.21)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.30.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: pypiwin32>=154 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ssd) (223)\n",
      "Requirement already satisfied: wmi in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from ssd) (1.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: pywin32>=223 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from pypiwin32>=154->ssd) (305)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harry parker\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\harry parker\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --user tensorflow opencv-python matplotlib imutils scikit-learn keras ssd pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image  \n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset\n",
    "data_path = \"data/WIDERFace\"\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "\n",
    "# Define the paths to the train, test, and val sets\n",
    "train_path = os.path.join(data_path, \"WIDER_train/images\")\n",
    "test_path = os.path.join(data_path, \"WIDER_test/images\")\n",
    "val_path = os.path.join(data_path, \"WIDER_val/images\")\n",
    "\n",
    "\n",
    "train_labels_path = (\"data/WIDERFace/wider_face_split/wider_face_train_bbx_gt.txt\")\n",
    "test_labels_path = (\"data/WIDERFace/wider_face_split/wider_face_test_filelist.txt\")\n",
    "val_labels_path = (\"data/WIDERFace/wider_face_split/wider_face_val_bbx_gt.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_wider_annotations(annotations_file):\n",
    "    \"\"\"\n",
    "    Load annotations for each image in the WIDER Face dataset from a text file.\n",
    "    \n",
    "    Args:\n",
    "    - annotations_file: str, path to the annotations file.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary where the keys are image file names and the values are lists of bounding boxes for that image.\n",
    "    \"\"\"\n",
    "    annotations = {}\n",
    "    \n",
    "    with open(annotations_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Split the line into components\n",
    "        components = line.split(' ')\n",
    "        image_path = components[0]\n",
    "        bbox = list(map(int, components[1:]))\n",
    "        \n",
    "        # Convert the image path to a file name\n",
    "        image_file = os.path.basename(image_path)\n",
    "        \n",
    "        # Add the bbox to the list of bboxes for this image\n",
    "        if image_file in annotations:\n",
    "            annotations[image_path].append(bbox)\n",
    "        else:\n",
    "            annotations[image_path] = [bbox]\n",
    "    \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 12880\n",
      "Number of test images: 16097\n",
      "Number of validation images: 3226\n",
      "data\\WIDERFace\\WIDER_train\\images/0--Parade/0_Parade_marchingband_1_483.jpg\n",
      "[[9, 485, 419, 48, 65, 1]]\n",
      "('data\\\\WIDERFace\\\\WIDER_train\\\\images/0--Parade/0_Parade_marchingband_1_483.jpg', [[9, 485, 419, 48, 65, 1]])\n"
     ]
    }
   ],
   "source": [
    "train_annotations = load_wider_annotations(train_labels_path)\n",
    "test_annotations = load_wider_annotations(test_labels_path)\n",
    "val_annotations = load_wider_annotations(val_labels_path)\n",
    "\n",
    "print(\"Number of training images: {}\".format(len(train_annotations)))\n",
    "print(\"Number of test images: {}\".format(len(test_annotations)))\n",
    "print(\"Number of validation images: {}\".format(len(val_annotations)))\n",
    "\n",
    "print(list(train_annotations.keys())[22])\n",
    "print(list(train_annotations.values())[22])\n",
    "print(list(train_annotations.items())[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_SIZE = 4\n",
    "\n",
    "def iou(boxA, boxB):\n",
    "  #evaluate the intersection points \n",
    "  xA = np.maximum(boxA[0], boxB[0])\n",
    "  yA = np.maximum(boxA[1], boxB[1])\n",
    "  xB = np.minimum(boxA[2], boxB[2])\n",
    "  yB = np.minimum(boxA[3], boxB[3])\n",
    "\n",
    "  # compute the area of intersection rectangle\n",
    "  interArea = np.maximum(0, xB - xA + 1) * np.maximum(0, yB - yA + 1)\n",
    "\n",
    "  # compute the area of both the prediction and ground-truth\n",
    "  # rectangles\n",
    "  boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "  boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "  #compute the union \n",
    "  unionArea = (boxAArea + boxBArea - interArea)\n",
    "\n",
    "  # return the intersection over union value\n",
    "  return interArea / unionArea\n",
    "\n",
    "#for a given box we predict the corrosponding bounding box \n",
    "def get_anchor(box):\n",
    "\n",
    "  max_iou = 0.0 \n",
    "  \n",
    "  matching_anchor  = [0, 0, 0, 0]\n",
    "  matching_index   = (0, 0)\n",
    "  i = 0 \n",
    "  j = 0 \n",
    "  \n",
    "  w , h = (1/ANCHOR_SIZE, 1/ANCHOR_SIZE)\n",
    "  \n",
    "  for x in np.linspace(0, 1, ANCHOR_SIZE +1)[:-1]:\n",
    "    j = 0 \n",
    "    for y in np.linspace(0, 1, ANCHOR_SIZE +1)[:-1]:\n",
    "      xmin = x \n",
    "      ymin = y\n",
    "      \n",
    "      xmax = (x + w) \n",
    "      ymax = (y + h) \n",
    "      \n",
    "      anchor_box = [xmin, ymin, xmax, ymax]\n",
    "      curr_iou = iou(box, anchor_box)\n",
    "      \n",
    "      #choose the location with the highest overlap \n",
    "      if curr_iou > max_iou:\n",
    "        matching_anchor = anchor_box\n",
    "        max_iou = curr_iou\n",
    "        matching_index = (i, j)\n",
    "      j += 1\n",
    "    i+= 1\n",
    "  return matching_anchor, matching_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_volume(boxes):\n",
    "  output = np.zeros((ANCHOR_SIZE, ANCHOR_SIZE, 5))\n",
    "  for box in boxes:\n",
    "    if max(box) == 0:\n",
    "      continue\n",
    "    _, (i, j) = get_anchor(box)\n",
    "    output[i,j, :] = [1] + box\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'data\\\\WIDERFace\\\\WIDER_train\\\\images/0--Parade/0_Parade_Parade_0_904.jpg 1 361 98 263 339 1\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m file_name \u001b[39m=\u001b[39m rows[i]\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[39m#get the number of boxes \u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m num_boxes \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(rows[i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     16\u001b[0m boxes \u001b[39m=\u001b[39m []\n\u001b[0;32m     18\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(file_name)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'data\\\\WIDERFace\\\\WIDER_train\\\\images/0--Parade/0_Parade_Parade_0_904.jpg 1 361 98 263 339 1\\n'"
     ]
    }
   ],
   "source": [
    "#read all the files for annotation \n",
    "annot_files = glob.glob('data/WIDERFace/wider_face_split/wider_face_train_bbx_gt.txt')\n",
    "data = {}\n",
    "for file in annot_files:  \n",
    "  with open(file, 'r') as f:\n",
    "    rows = f.readlines()\n",
    "    \n",
    "  j = len(rows)\n",
    "  i = 0   \n",
    "  while(i < j):\n",
    "    #get the file name\n",
    "    file_name = rows[i].replace('\\n', '')+'.jpg'\n",
    "    \n",
    "    #get the number of boxes \n",
    "    num_boxes = int(rows[i+1])\n",
    "    boxes = []\n",
    "    \n",
    "    img = Image.open(file_name)\n",
    "    w, h = img.size\n",
    "    #get all the bounding boxes\n",
    "    for k in range(1, num_boxes+1):\n",
    "      box = rows[i+1+k]\n",
    "      box = box.split(' ')[0:5]\n",
    "      box = [float(x) for x in box]\n",
    "      \n",
    "      #convert ellipse to a box \n",
    "      xmin = int(box[3]- box[1])\n",
    "      ymin = int(box[4]- box[0])\n",
    "      xmax = int(xmin + box[1]*2)\n",
    "      ymax = int(ymin + box[0]*2)\n",
    "      boxes.append([xmin/w, ymin/h, xmax/w, ymax/h])\n",
    "    #conver the boxes to a volume of fixed size \n",
    "    data[file_name] = create_volume(boxes)\n",
    "    i = i + num_boxes+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 240\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input \n",
    "from keras.layers import Flatten, Dropout, BatchNormalization, Concatenate, Reshape, GlobalAveragePooling2D, Reshape\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "GRID_SIZE = 10\n",
    "NUM_BOXES_PER_CELL = 2\n",
    "\n",
    "\n",
    "def parse_image(filename, label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [240, 240])\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def parse_label(filename, annotations):\n",
    "    image_annotations = annotations[tf.strings.basename(filename).numpy().decode('utf-8')]\n",
    "\n",
    "    # Create an empty grid of cells, each of which will predict up to `NUM_BOXES_PER_CELL` bounding boxes\n",
    "    grid = np.zeros((GRID_SIZE, GRID_SIZE, NUM_BOXES_PER_CELL, 5))\n",
    "\n",
    "    # Convert the annotations for each bounding box into the appropriate format\n",
    "    for annotation in image_annotations:\n",
    "        # Extract the bounding box coordinates and class label\n",
    "        class_label, x_min, y_min, w, h = annotation\n",
    "\n",
    "        # Calculate the center coordinates of the bounding box\n",
    "        x_center = x_min + w/2\n",
    "        y_center = y_min + h/2\n",
    "\n",
    "        # Map the center coordinates to the appropriate cell in the grid\n",
    "        cell_x = int(x_center * GRID_SIZE)\n",
    "        cell_y = int(y_center * GRID_SIZE)\n",
    "\n",
    "        # Find the first empty bounding box slot in the cell and store the box information there\n",
    "        for i in range(NUM_BOXES_PER_CELL):\n",
    "            if grid[cell_y, cell_x, i, 0] == 0:\n",
    "                grid[cell_y, cell_x, i] = [class_label, x_min, y_min, w, h]\n",
    "                break\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "def create_dataset(annotations_path, batch_size=32, shuffle=True):\n",
    "    annotations = load_wider_annotations(annotations_path)\n",
    "    image_paths = tf.constant([os.path.join(filename) for filename in annotations.keys()])\n",
    "    labels = tf.constant([annotations[filename] for filename in annotations.keys()])\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(annotations))\n",
    "    dataset = dataset.map(lambda filename, label: (parse_image(filename, label), parse_label(filename, annotations)), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Harry Parker\\AppData\\Local\\Temp\\ipykernel_33992\\3421359932.py\", line 54, in None  *\n        lambda filename, label: (parse_image(filename, label), parse_label(filename, annotations))\n    File \"C:\\Users\\Harry Parker\\AppData\\Local\\Temp\\ipykernel_33992\\3421359932.py\", line 19, in parse_label  *\n        image_annotations = annotations[tf.strings.basename(filename).numpy().decode('utf-8')]\n\n    AttributeError: module 'tensorflow._api.v2.strings' has no attribute 'basename'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[39m=\u001b[39m create_dataset(train_labels_path, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      2\u001b[0m val_dataset \u001b[39m=\u001b[39m create_dataset(val_labels_path, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m test_dataset \u001b[39m=\u001b[39m create_dataset(test_labels_path, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[64], line 54\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[1;34m(annotations_path, batch_size, shuffle)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mif\u001b[39;00m shuffle:\n\u001b[0;32m     53\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mshuffle(buffer_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(annotations))\n\u001b[1;32m---> 54\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m filename, label: (parse_image(filename, label), parse_label(filename, annotations)), num_parallel_calls\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mAUTOTUNE)\n\u001b[0;32m     55\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mbatch(batch_size)\n\u001b[0;32m     56\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mprefetch(buffer_size\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2296\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2294\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39m, map_func, preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   2295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2296\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[0;32m   2297\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2298\u001b[0m       map_func,\n\u001b[0;32m   2299\u001b[0m       num_parallel_calls,\n\u001b[0;32m   2300\u001b[0m       deterministic,\n\u001b[0;32m   2301\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   2302\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5540\u001b[0m, in \u001b[0;36mParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5538\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[0;32m   5539\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m-> 5540\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m   5541\u001b[0m     map_func,\n\u001b[0;32m   5542\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[0;32m   5543\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[0;32m   5544\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[0;32m   5545\u001b[0m \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5546\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deterministic \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:263\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    259\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    261\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 263\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    264\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:226\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    218\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m    227\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    228\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    229\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:192\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mvalidate_inputs_with_signature(args, kwargs)\n\u001b[0;32m    191\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 192\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[0;32m    193\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    194\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m    195\u001b[0m       concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:157\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    155\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:360\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m    358\u001b[0m   args, kwargs \u001b[39m=\u001b[39m generalized_func_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(args, kwargs)\n\u001b[0;32m    362\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:284\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m    281\u001b[0m ]\n\u001b[0;32m    282\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m    283\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 284\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m    286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m    287\u001b[0m         args,\n\u001b[0;32m    288\u001b[0m         kwargs,\n\u001b[0;32m    289\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    290\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m    291\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m    292\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m    293\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m    295\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m    296\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    297\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    298\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    299\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:240\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    235\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    236\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    237\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    238\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    241\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    242\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:171\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    170\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 171\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    172\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32mC:\\Users\\HARRYP~1\\AppData\\Local\\Temp\\__autograph_generated_file4f_snr3j.py:6\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(filename, label)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 6\u001b[0m     tf__lam \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m filename, label: ag__\u001b[39m.\u001b[39;49mwith_function_scope(\u001b[39mlambda\u001b[39;49;00m lscope: (ag__\u001b[39m.\u001b[39;49mconverted_call(parse_image, (filename, label), \u001b[39mNone\u001b[39;49;00m, lscope), ag__\u001b[39m.\u001b[39;49mconverted_call(parse_label, (filename, annotations), \u001b[39mNone\u001b[39;49;00m, lscope)), \u001b[39m'\u001b[39;49m\u001b[39mlscope\u001b[39;49m\u001b[39m'\u001b[39;49m, ag__\u001b[39m.\u001b[39;49mSTD)\n\u001b[0;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\core\\function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[1;34m(thunk, scope_name, options)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m FunctionScope(\u001b[39m'\u001b[39m\u001b[39mlambda_\u001b[39m\u001b[39m'\u001b[39m, scope_name, options) \u001b[39mas\u001b[39;00m scope:\n\u001b[1;32m--> 113\u001b[0m   \u001b[39mreturn\u001b[39;00m thunk(scope)\n",
      "File \u001b[1;32mC:\\Users\\HARRYP~1\\AppData\\Local\\Temp\\__autograph_generated_file4f_snr3j.py:6\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(lscope)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 6\u001b[0m     tf__lam \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m filename, label: ag__\u001b[39m.\u001b[39mwith_function_scope(\u001b[39mlambda\u001b[39;00m lscope: (ag__\u001b[39m.\u001b[39mconverted_call(parse_image, (filename, label), \u001b[39mNone\u001b[39;00m, lscope), ag__\u001b[39m.\u001b[39;49mconverted_call(parse_label, (filename, annotations), \u001b[39mNone\u001b[39;49;00m, lscope)), \u001b[39m'\u001b[39m\u001b[39mlscope\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mSTD)\n\u001b[0;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[0;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[1;32mC:\\Users\\HARRYP~1\\AppData\\Local\\Temp\\__autograph_generated_fileccgsp5c8.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__parse_label\u001b[1;34m(filename, annotations)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m image_annotations \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(annotations)[ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mstrings\u001b[39m.\u001b[39;49mbasename, (ag__\u001b[39m.\u001b[39mld(filename),), \u001b[39mNone\u001b[39;00m, fscope)\u001b[39m.\u001b[39mnumpy, (), \u001b[39mNone\u001b[39;00m, fscope)\u001b[39m.\u001b[39mdecode, (\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39mNone\u001b[39;00m, fscope)]\n\u001b[0;32m     11\u001b[0m grid \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(np)\u001b[39m.\u001b[39mzeros, ((ag__\u001b[39m.\u001b[39mld(GRID_SIZE), ag__\u001b[39m.\u001b[39mld(GRID_SIZE), ag__\u001b[39m.\u001b[39mld(NUM_BOXES_PER_CELL), \u001b[39m5\u001b[39m),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_2\u001b[39m():\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Harry Parker\\AppData\\Local\\Temp\\ipykernel_33992\\3421359932.py\", line 54, in None  *\n        lambda filename, label: (parse_image(filename, label), parse_label(filename, annotations))\n    File \"C:\\Users\\Harry Parker\\AppData\\Local\\Temp\\ipykernel_33992\\3421359932.py\", line 19, in parse_label  *\n        image_annotations = annotations[tf.strings.basename(filename).numpy().decode('utf-8')]\n\n    AttributeError: module 'tensorflow._api.v2.strings' has no attribute 'basename'\n"
     ]
    }
   ],
   "source": [
    "train_dataset = create_dataset(train_labels_path, shuffle=True)\n",
    "val_dataset = create_dataset(val_labels_path, shuffle=False)\n",
    "test_dataset = create_dataset(test_labels_path, shuffle=False)\n",
    "\n",
    "# Retrieve the first element from the dataset\n",
    "example = next(iter(train_dataset))\n",
    "\n",
    "# Print the contents of the element\n",
    "print('Image shape:', example[0].shape)\n",
    "print('Label:', example[1])\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_annot(img, boxes):  \n",
    "\n",
    "  img = img.numpy()\n",
    "  boxes = boxes.numpy()\n",
    "  boxes = tf.reshape(boxes, [ANCHOR_SIZE, ANCHOR_SIZE, 5])\n",
    "\n",
    "  \n",
    "  for i in range(0, ANCHOR_SIZE):\n",
    "    for j in range(0, ANCHOR_SIZE):\n",
    "      box = boxes[i, j, 1:] * IMG_SIZE\n",
    "      label = boxes[i, j, 0]\n",
    "      \n",
    "      if np.max(box) > 0:\n",
    "        img = cv2.rectangle(img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (1, 0, 0), 1)\n",
    "\n",
    "  plt.axis('off')\n",
    "  plt.imshow(img)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 6 values, but the requested shape has 80 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m train_dataset:\n\u001b[1;32m----> 3\u001b[0m   plot_annot(x[\u001b[39m0\u001b[39;49m], y[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      4\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[45], line 5\u001b[0m, in \u001b[0;36mplot_annot\u001b[1;34m(img, boxes)\u001b[0m\n\u001b[0;32m      3\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      4\u001b[0m boxes \u001b[39m=\u001b[39m boxes\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m----> 5\u001b[0m boxes \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mreshape(boxes, [ANCHOR_SIZE, ANCHOR_SIZE, \u001b[39m5\u001b[39;49m])\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, ANCHOR_SIZE):\n\u001b[0;32m      9\u001b[0m   \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, ANCHOR_SIZE):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 6 values, but the requested shape has 80 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset:\n",
    "  \n",
    "  plot_annot(x[0], y[0])\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(fs, x, activation = 'relu'):\n",
    "  conv  = Conv2D(fs, (3, 3), padding = 'same', activation = activation)(x)\n",
    "  bnrm  = BatchNormalization()(conv)\n",
    "  drop  = Dropout(0.5)(bnrm)\n",
    "  return drop\n",
    "\n",
    "def residual_block(fs, x):\n",
    "  y = conv_block(fs, x)\n",
    "  y = conv_block(fs, y)\n",
    "  y = conv_block(fs, y)\n",
    "  return Concatenate(axis = -1)([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape = (IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "block1 = residual_block(16, inp)\n",
    "pool1  = MaxPooling2D(pool_size = (2, 2))(block1)\n",
    "block2 = residual_block(32, pool1)\n",
    "pool2  = MaxPooling2D(pool_size = (2, 2))(block2)\n",
    "block3 = residual_block(64, pool2)\n",
    "pool3  = MaxPooling2D(pool_size = (2, 2))(block3)\n",
    "block4 = residual_block(128, pool3)\n",
    "pool4  = MaxPooling2D(pool_size = (2, 2))(block4)\n",
    "block5 = residual_block(256, pool4)\n",
    "pool5  = MaxPooling2D(pool_size = (2, 2))(block5)\n",
    "out  = Conv2D(5, (3, 3), padding = 'same', activation = 'sigmoid')(pool5)\n",
    "\n",
    "#create a model with one input and two outputs \n",
    "model = tf.keras.models.Model(inputs = inp, outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 240, 240, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 240, 240, 16  448         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 240, 240, 16  64         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 240, 240, 16  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 240, 240, 16  2320        ['dropout[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 240, 240, 16  64         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 240, 240, 16  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 240, 240, 16  2320        ['dropout_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 240, 240, 16  64         ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 240, 240, 16  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 240, 240, 19  0           ['input_1[0][0]',                \n",
      "                                )                                 'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 120, 120, 19  0           ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 120, 120, 32  5504        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 120, 120, 32  128        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 120, 120, 32  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 120, 120, 32  9248        ['dropout_3[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 120, 120, 32  128        ['conv2d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 120, 120, 32  0           ['batch_normalization_4[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 120, 120, 32  9248        ['dropout_4[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 120, 120, 32  128        ['conv2d_5[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 120, 120, 32  0           ['batch_normalization_5[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 120, 120, 51  0           ['max_pooling2d[0][0]',          \n",
      "                                )                                 'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 60, 60, 51)  0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 60, 60, 64)   29440       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 60, 60, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 60, 60, 64)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 60, 60, 64)   36928       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 60, 60, 64)  256         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 60, 60, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 60, 60, 64)   36928       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 60, 60, 64)  256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 60, 60, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 60, 60, 115)  0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 30, 30, 115)  0          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 30, 30, 128)  132608      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 30, 30, 128)  512        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 30, 30, 128)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 30, 30, 128)  147584      ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 30, 30, 128)  512        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 30, 30, 128)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 30, 30, 128)  147584      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 30, 30, 128)  512        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 30, 30, 128)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 30, 30, 243)  0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 243)  0          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 15, 15, 256)  560128      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 15, 15, 256)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 15, 15, 256)  590080      ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 15, 15, 256)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 15, 15, 256)  590080      ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 15, 15, 256)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 15, 15, 499)  0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 7, 7, 499)   0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 7, 7, 5)      22460       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,328,860\n",
      "Trainable params: 2,325,884\n",
      "Non-trainable params: 2,976\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred, y):\n",
    "  \n",
    "  #extract the boxes that have values (i.e discard boxes that are zeros)\n",
    "  mask = y[...,0]\n",
    "  boxA    = tf.boolean_mask(y, mask)\n",
    "  boxB    = tf.boolean_mask(pred, mask)\n",
    "  \n",
    "  prediction_error = tf.keras.losses.binary_crossentropy(y[...,0], pred[...,0])\n",
    "\n",
    "  detection_error = tf.losses.absolute_difference(boxA[...,1:], boxB[...,1:]) \n",
    "  \n",
    "  \n",
    "  return tf.reduce_mean(prediction_error) + 10*detection_error\n",
    "           \n",
    "def grad(model, x, y):\n",
    "  #record the gradient\n",
    "  with tf.GradientTape() as tape:\n",
    "    pred = model(x)\n",
    "    value = loss(pred, y)\n",
    "  #return the gradient of the loss function with respect to the model variables \n",
    "  return tape.gradient(value, model.trainable_variables)\n",
    "\n",
    "batches_per_epoch = len(train_dataset)\n",
    "lr_decay = (1./0.75 -1)/batches_per_epoch\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "#initialize the history to record the metrics \n",
    "train_loss_history = tf.metrics.Mean('train_loss')\n",
    "\n",
    "test_loss_history = tf.metrics.Mean('test_loss')\n",
    "\n",
    "best_loss = 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 240, 240, 3), found shape=(240, 240, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m   \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m train_dataset:\n\u001b[1;32m----> 4\u001b[0m     pred \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m      5\u001b[0m     grads \u001b[39m=\u001b[39m grad(model, x, y)\n\u001b[0;32m      7\u001b[0m     \u001b[39m#update the paramters of the model \u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py:295\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m spec_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[39mif\u001b[39;00m spec_dim \u001b[39m!=\u001b[39m dim:\n\u001b[1;32m--> 295\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    297\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mincompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected shape=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfound shape=\u001b[39m\u001b[39m{\u001b[39;00mdisplay_shape(x\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 240, 240, 3), found shape=(240, 240, 3)"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs + 1):\n",
    "  \n",
    "  for x, y in train_dataset:\n",
    "    pred = model(x)\n",
    "    grads = grad(model, x, y)\n",
    "\n",
    "    #update the paramters of the model \n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables), global_step = tf.train.get_or_create_global_step())\n",
    "\n",
    "    #record the metrics of the current batch \n",
    "    loss_value = loss(pred, y)\n",
    "    \n",
    "    #calcualte the metrics of the current batch\n",
    "    train_loss_history(loss_value)\n",
    "    \n",
    "  #loop over the test dataset \n",
    "  for x, y in test_dataset:\n",
    "    pred = model(x)\n",
    "    \n",
    "    #calcualte the metrics of the current batch \n",
    "    loss_value = loss(pred, y)\n",
    "    \n",
    "    #record the values of the metrics \n",
    "    test_loss_history(loss_value)\n",
    "        \n",
    "  #print out the results \n",
    "  print(\"epoch: [{0:d}/{1:d}], Train: [loss: {2:0.4f}], Test: [loss: {3:0.4f}]\".\n",
    "       format(i, epochs, train_loss_history.result(), \n",
    "              test_loss_history.result()))\n",
    "  \n",
    "  current_loss = test_loss_history.result().numpy()\n",
    "  \n",
    "  #save the best model \n",
    "  if current_loss  < best_loss:\n",
    "    best_loss = current_loss\n",
    "    print('saving best model with loss ', current_loss)\n",
    "    model.save('keras.h5')\n",
    "    \n",
    "  #clear the history after each epoch \n",
    "  train_loss_history.init_variables()\n",
    "  test_loss_history.init_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "best_model = load_model('keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the predicted bounding box\n",
    "def plot_pred(img_id):\n",
    "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "  raw = cv2.imread(img_id)[:,:,::-1]\n",
    "  \n",
    "  h, w = (512, 512)\n",
    "  \n",
    "  img = cv2.resize(raw, (IMG_SIZE, IMG_SIZE)).astype('float32')\n",
    "  img = np.expand_dims(img, 0)/255. \n",
    "  \n",
    "  boxes = best_model(img).numpy()[0]\n",
    "\n",
    "  raw = cv2.resize(raw, (w, h))\n",
    "    \n",
    "  for i in range(0, ANCHOR_SIZE):\n",
    "    for j in range(0, ANCHOR_SIZE):\n",
    "      box = boxes[i, j, 1:] * w\n",
    "      lbl = round(boxes[i, j, 0], 2)\n",
    "      if lbl > 0.5:\n",
    "        color = [random.randint(0, 255) for _ in range(0, 3)]\n",
    "        raw = cv2.rectangle(raw, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, 3) \n",
    "        raw = cv2.rectangle(raw, (int(box[0]), int(box[1])-30), (int(box[0])+70, int(box[1])), color, cv2.FILLED)\n",
    "        raw = cv2.putText(raw, str(lbl), (int(box[0]), int(box[1])), font, 1, (255, 255, 255), 2)\n",
    "        \n",
    "\n",
    "  plt.axis('off')\n",
    "  plt.imshow(raw)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_NumpyIterator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img_id \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(test_dataset\u001b[39m.\u001b[39;49mtake(\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mas_numpy_iterator()[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m      2\u001b[0m plot_pred(img_id)\n",
      "\u001b[1;31mTypeError\u001b[0m: '_NumpyIterator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "img_id = np.random.choice(test_dataset.take(1).as_numpy_iterator()[0][0].shape[0])\n",
    "plot_pred(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_pred(\u001b[39m'\u001b[39;49m\u001b[39mtest.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[45], line 5\u001b[0m, in \u001b[0;36mplot_pred\u001b[1;34m(img_id)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_pred\u001b[39m(img_id):\n\u001b[0;32m      3\u001b[0m   font \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mFONT_HERSHEY_SIMPLEX\n\u001b[1;32m----> 5\u001b[0m   raw \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(img_id)[:,:,::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[0;32m      7\u001b[0m   h, w \u001b[39m=\u001b[39m (\u001b[39m512\u001b[39m, \u001b[39m512\u001b[39m)\n\u001b[0;32m      9\u001b[0m   img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(raw, (IMG_SIZE, IMG_SIZE))\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "plot_pred('test.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
